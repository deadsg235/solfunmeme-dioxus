

Conversation with Gemini
vendor_leptos_any_spawner_src.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_icu4x_provider_source_tests_data_cldr_cldrdatesfull_main_ccp.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] ğŸŒÃ—2 ğŸŒÃ—1



It seems like you've provided two file paths along with a breakdown of various programming language constructs found within them, represented by emojis. You've also included a separate line with "words mapped to emojis".

Could you please clarify what you'd like me to do with this information? For example, are you looking for:

A comparison of the two files based on the listed constructs?

An explanation of what each emoji represents in the context of programming constructs?

A task that involves analyzing or processing these files or their contents?

Something else entirely?

Please provide more context or a specific question, and I'll do my best to assist you!






its a summary from a file


You're providing a summary of the contents of the files vendor_leptos_any_spawner_src.rs.json and vendor_icu4x_provider_source_tests_data_cldr_cldrdatesfull_main_ccp.rs.json.

Based on your input, here's what I can tell you about the summary:

Both files appear to contain similar (if not identical) programming language constructs. For each file, the summary indicates the presence of:

ğŸ¨(attrs)Ã—1: One attribute.

ğŸš§(delimiter)Ã—1: One delimiter.

ğŸŒ±(fields)Ã—1: One set of fields (likely in a struct or enum).

ğŸ†”(ident)Ã—6: Six identifiers (names of variables, functions, types, etc.).

ğŸ“š(items)Ã—1: One item (a top-level declaration like a function, struct, or module).

âœ…(list)Ã—1: One list.

ğŸ’¡(lit)Ã—1: One literal (a constant value like a number or string).

ğŸ§ (meta)Ã—2: Two metadata elements.

ğŸ”‘(name_value)Ã—1: One name-value pair.

ğŸ›¤ï¸(path)Ã—3: Three paths (e.g., for imports or type references).

ğŸ§©(segments)Ã—2: Two segments (likely parts of a path).

ğŸ“(str)Ã—1: One string.

ğŸ›ï¸ğŸ§±(struct)Ã—1: One struct definition.

ğŸ¨(style)Ã—2: Two style-related elements (could be for formatting or attributes).

ğŸŸï¸(tokens)Ã—1: One token (a basic unit of code).

ğŸŒ³(tree)Ã—2: Two tree-like structures (could refer to abstract syntax trees or similar hierarchical data).

ğŸ”—(use)Ã—1: One use declaration (for importing modules or items).

ğŸ’(value)Ã—1: One value.

ğŸ‘€(vis)Ã—1: One visibility modifier (e.g., pub for public).

Additionally, you've mapped some words to emojis:

ğŸŒ and ğŸŒ are used to represent Ã—2 and Ã—1 respectively. This specific mapping isn't directly related to the file content summary but rather to a count notation you've used.

In essence, these are both .json files that seem to describe the abstract syntax tree (AST) or some structural breakdown of Rust code (given the .rs extension in the original file names and common Rust constructs like struct, use, pub). The summaries suggest a very similar, if not identical, structure for the Rust code they are summarizing.






we can imagine a now a topological object with this size


You've provided summaries of two files, vendor_leptos_any_spawner_src.rs.json and vendor_icu4x_provider_source_tests_data_cldr_cldrdatesfull_main_ccp.rs.json, detailing the count of various programming constructs within them. You've also indicated that these summaries describe the "size" of a "topological object."

It sounds like you're using the count of these programming constructs (like attributes, identifiers, structs, etc.) as a way to quantify or characterize the "shape" or "complexity" of the code represented by these files, much like a topological object has properties of size and form.

What We Can Infer About Your "Topological Object"
Based on the summaries, your "topological objects" (the code represented by each file) appear to be identical in terms of their constituent elements. Both files consistently contain:

One attribute, delimiter, field set, list, literal, name-value pair, string, struct, token, use declaration, value, and visibility modifier.

Two metadata elements, style elements, and tree-like structures.

Three paths.

Six identifiers.

One item.

This precise match suggests that, from the perspective of these enumerated programming constructs, the two code structures are isomorphic or, at the very least, topologically equivalent based on your chosen metrics. They contain the same number of each defined "feature," implying a similar structural complexity or arrangement.

Further Exploration
If you're thinking of these code structures as topological objects, we could explore this idea further. For instance, you might consider:

Which programming constructs represent "nodes" and "edges" in your topological graph?

How does the "connectivity" between these constructs (e.g., how an attribute relates to a struct, or how paths link segments) define the object's shape?

What other metrics could you extract to differentiate or compare these "objects" if they were not identical by these initial counts?

Do you have a particular goal in mind for analyzing these "topological objects" or would you like to explore how different metrics could reveal more about their "shape"?






src_model_lean_types.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€



You've provided another summary of a file, src_model_lean_types.rs.json, using the same emoji-based notation to represent programming language constructs and their counts.

Just like the previous two files you presented, this src_model_lean_types.rs.json file also shows an identical breakdown of programming constructs:

ğŸ¨(attrs)Ã—1: One attribute.

ğŸš§(delimiter)Ã—1: One delimiter.

ğŸŒ±(fields)Ã—1: One set of fields.

ğŸ†”(ident)Ã—6: Six identifiers.

ğŸ“š(items)Ã—1: One item.

âœ…(list)Ã—1: One list.

ğŸ’¡(lit)Ã—1: One literal.

ğŸ§ (meta)Ã—2: Two metadata elements.

ğŸ”‘(name_value)Ã—1: One name-value pair.

ğŸ›¤ï¸(path)Ã—3: Three paths.

ğŸ§©(segments)Ã—2: Two segments.

ğŸ“(str)Ã—1: One string.

ğŸ›ï¸ğŸ§±(struct)Ã—1: One struct definition.

ğŸ¨(style)Ã—2: Two style-related elements.

ğŸŸï¸(tokens)Ã—1: One token.

ğŸŒ³(tree)Ã—2: Two tree-like structures.

ğŸ”—(use)Ã—1: One use declaration.

ğŸ’(value)Ã—1: One value.

ğŸ‘€(vis)Ã—1: One visibility modifier.

Conclusion Regarding Your "Topological Objects"
With this third file, src_model_lean_types.rs.json, exhibiting the exact same "size" (i.e., the same count of each specific programming construct) as the previous two (vendor_leptos_any_spawner_src.rs.json and vendor_icu4x_provider_source_tests_data_cldr_cldrdatesfull_main_ccp.rs.json), it reinforces the idea that, based on your chosen metrics, these three pieces of code possess identical structural properties.

If you're conceptualizing these as "topological objects," then all three objects, by this summary, are topologically indistinguishable from each other. They share the same quantitative composition of their fundamental building blocks.

Are you providing these as examples of a specific kind of code structure, or do you have a question about what this consistency implies or how to further differentiate them?






[words mapped to emojis] 6ï¸âƒ£Ã—1 â±ï¸Ã—1 ğŸ“–Ã—1

vendor_hyperutil_src_client_legacy_connect_proxy_socks.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_rustix_src_backend_linux_raw_mm.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

lean.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—3 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—1 ğŸ†”(ident)Ã—15 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—2 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 âš™ï¸(op)Ã—4 â¬…ï¸(output)Ã—1 ğŸ›¤ï¸(path)Ã—9 â€¼ï¸(punct)Ã—4 ğŸ§©(segments)Ã—3 â†”ï¸(spacing)Ã—4 ğŸ“œ(stmts)Ã—1 ğŸŒŠ(stream)Ã—1 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—2 ğŸŒ³(tree)Ã—8 ğŸ”—(use)Ã—2 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸš§ğŸš§ğŸ¦€âš™ï¸ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â¡ï¸ğŸ“šâœ…ğŸ’¡ğŸ’¡ğŸª„ğŸ§ âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸŒŠğŸ¨ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—ğŸ”—ğŸ‘€

[words mapped to emojis] ğŸ“±Ã—1

vendor_borsh_docs_criterion_de_account_bincode_report.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] â±ï¸Ã—1 ğŸ“–Ã—1

vendor_unicase_github_workflows.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_walkdir_walkdirlist.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] âœ…Ã—1

vendor_formats.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_ahocorasick_benchmarks_regexes.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_icu4x_provider_source_tests_data_cldr_cldrcalbuddhistfull_main_srLatn.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] ğŸŒÃ—2 ğŸŒÃ—1

vendor_icu4x_provider_source_data_debug_datetime_patterns_date_coptic_v1_m0de.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] â°Ã—1 â›ªÃ—1 ğŸŒÃ—1

vendor_windowsrs_crates_tests_misc_sys_tests.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_borsh_docs_criterion_ser_header_speedy_idx3size108473_report_both.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] 3ï¸âƒ£Ã—1 â±ï¸Ã—1 ğŸ“–Ã—1

vendor_borsh_docs_criterion_de_transaction_cbor_idx7size371_report.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] 7ï¸âƒ£Ã—1 â±ï¸Ã—1 ğŸ“–Ã—1 ğŸ“¦Ã—1

vendor_hashes_fsb_tests.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_icu4x_components_locale_src_fallback.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] ğŸŒÃ—1

vendor_manganis_testpackage.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_vcpkgrs_testdata_nostatus_installed_vcpkg_updates.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

vendor_icu4x_provider_source_data_debug_unit_ids_v1_permille.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ†”(ident)Ã—6 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ›¤ï¸(path)Ã—3 ğŸ§©(segments)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—2 ğŸ”—(use)Ã—1 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸŒ±ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”—ğŸ’ğŸ‘€

[words mapped to emojis] ğŸŒÃ—1



You've continued to provide summaries of .rs.json files, detailing the counts of various programming constructs within them, similar to your previous inputs. It's clear you're using this emoji-based notation to describe the composition of these code files.

Let's break down the information you've provided:

Analysis of Code Structure Summaries
You've presented 13 new file summaries, alongside some additional word-to-emoji mappings.

Consistent Structure (Group 1)
Most of the files you've listed show an identical structural breakdown of programming constructs. This means that, based on your metrics, they are all "topologically equivalent" in terms of their component counts. These files include:

vendor_hyperutil_src_client_legacy_connect_proxy_socks.rs.json

vendor_rustix_src_backend_linux_raw_mm.rs.json

vendor_borsh_docs_criterion_de_account_bincode_report.rs.json

vendor_unicase_github_workflows.rs.json

vendor_walkdir_walkdirlist.rs.json

vendor_formats.rs.json

vendor_ahocorasick_benchmarks_regexes.rs.json

vendor_icu4x_provider_source_tests_data_cldr_cldrcalbuddhistfull_main_srLatn.rs.json

vendor_icu4x_provider_source_data_debug_datetime_patterns_date_coptic_v1_m0de.rs.json

vendor_windowsrs_crates_tests_misc_sys_tests.rs.json

vendor_borsh_docs_criterion_ser_header_speedy_idx3size108473_report_both.rs.json

vendor_borsh_docs_criterion_de_transaction_cbor_idx7size371_report.rs.json

vendor_hashes_fsb_tests.rs.json

vendor_icu4x_components_locale_src_fallback.rs.json

vendor_manganis_testpackage.rs.json

vendor_vcpkgrs_testdata_nostatus_installed_vcpkg_updates.rs.json

vendor_icu4x_provider_source_data_debug_unit_ids_v1_permille.rs.json

For each of these files, the summary shows:

ğŸ¨(attrs)Ã—1, ğŸš§(delimiter)Ã—1, ğŸŒ±(fields)Ã—1, ğŸ†”(ident)Ã—6, ğŸ“š(items)Ã—1, âœ…(list)Ã—1, ğŸ’¡(lit)Ã—1, ğŸ§ (meta)Ã—2, ğŸ”‘(name_value)Ã—1, ğŸ›¤ï¸(path)Ã—3, ğŸ§©(segments)Ã—2, ğŸ“(str)Ã—1, ğŸ›ï¸ğŸ§±(struct)Ã—1, ğŸ¨(style)Ã—2, ğŸŸï¸(tokens)Ã—1, ğŸŒ³(tree)Ã—2, ğŸ”—(use)Ã—1, ğŸ’(value)Ã—1, ğŸ‘€(vis)Ã—1.

This remarkable consistency suggests that these .json files might be generated from a template or represent very small, simple Rust code snippets that share a common underlying structure.

Unique Structure (Group 2)
However, one file stands out as being significantly different:

lean.rs.json

This file has a much more diverse and higher count of constructs, indicating a more complex or different kind of code structure compared to the others. Its summary is:

ğŸ¨(attrs)Ã—1, ğŸš§(delimiter)Ã—3, ğŸ¦€âš™ï¸(fn)Ã—1, ğŸ‘¥(group)Ã—1, ğŸ†”(ident)Ã—15, â¡ï¸(inputs)Ã—1, ğŸ“š(items)Ã—1, âœ…(list)Ã—1, ğŸ’¡(lit)Ã—2, ğŸª„(macro)Ã—1, ğŸ§ (meta)Ã—1, âš™ï¸(op)Ã—4, â¬…ï¸(output)Ã—1, ğŸ›¤ï¸(path)Ã—9, â€¼ï¸(punct)Ã—4, ğŸ§©(segments)Ã—3, â†”ï¸(spacing)Ã—4, ğŸ“œ(stmts)Ã—1, ğŸŒŠ(stream)Ã—1, ğŸ¨(style)Ã—1, ğŸŸï¸(tokens)Ã—2, ğŸŒ³(tree)Ã—8, ğŸ”—(use)Ã—2, ğŸ‘€(vis)Ã—1.

Key differences for lean.rs.json include:

More identifiers (15 vs. 6)

More delimiters (3 vs. 1)

Presence of a function (ğŸ¦€âš™ï¸(fn)Ã—1) and its â¡ï¸(inputs)Ã—1 and â¬…ï¸(output)Ã—1

Presence of a macro (ğŸª„(macro)Ã—1)

More literals (2 vs. 1)

More paths (9 vs. 3)

Presence of punctuation (â€¼ï¸(punct)Ã—4)

More segments (3 vs. 2)

More spacing (â†”ï¸(spacing)Ã—4)

Presence of statements (ğŸ“œ(stmts)Ã—1)

Presence of a stream (ğŸŒŠ(stream)Ã—1)

More tokens (2 vs. 1)

More trees (8 vs. 2)

More use declarations (2 vs. 1)

This suggests that lean.rs.json represents a more functional or procedural code snippet, possibly containing a function definition, macro usage, and more complex expressions, making it topologically distinct from the other files.

Word-to-Emoji Mappings
You've also provided additional word-to-emoji mappings, which seem to be for counting:

6ï¸âƒ£Ã—1

â±ï¸Ã—1

ğŸ“–Ã—1

ğŸ“±Ã—1

ğŸŒÃ—2

ğŸŒÃ—1

â°Ã—1

â›ªÃ—1

3ï¸âƒ£Ã—1

7ï¸âƒ£Ã—1

ğŸ“¦Ã—1

âœ…Ã—1

These mappings appear to be separate from the structural summaries of the .rs.json files themselves, perhaps for a different level of analysis or simply for notation within your system.

It's fascinating how you're using these summaries to describe "topological objects" of code. The vast majority of your files seem to share a common structural footprint, while lean.rs.json stands out as a more intricate "object."

Are you trying to categorize these files based on their structural complexity, or do you have a specific question about why so many of them share the same "topological" characteristics?






test_components.rs.json | â¬œ(_)Ã—2 âŸ¨âŸ©(angle_bracketed)Ã—9 ğŸ“¢(args)Ã—17 ğŸ™ï¸(arguments)Ã—9 ğŸ› ï¸(arms)Ã—3 ğŸ¨(attrs)Ã—6 ğŸ(base)Ã—1 ğŸ§±(block)Ã—8 ğŸƒ(body)Ã—134 ğŸ“(call)Ã—6 ğŸ”€(cast)Ã—1 ğŸ•¸ï¸(closure)Ã—6 :(colon2_token)Ã—2 :(colon_token)Ã—3 ğŸš§(delimiter)Ã—180 ğŸ“¦(elem)Ã—6 ğŸ“¦(elems)Ã—3 ğŸ²(enum)Ã—2 ğŸ§®(expr)Ã—23 ğŸŒ¿(field)Ã—1 ğŸŒ±(fields)Ã—87 ğŸ¦€âš™ï¸(fn)Ã—6 ğŸ¦€(func)Ã—6 ğŸ‘¥(group)Ã—137 ğŸ†”(ident)Ã—842 ğŸš¦(init)Ã—7 â¡ï¸(inputs)Ã—12 #ï¸âƒ£(int)Ã—1 ğŸ“š(items)Ã—1 ğŸ“Œ(let)Ã—7 â³(lifetime)Ã—4 âœ…(list)Ã—3 ğŸ’¡(lit)Ã—234 ğŸª„(macro)Ã—54 ğŸ¯(match)Ã—3 ğŸ§ (meta)Ã—6 ğŸ”§(method)Ã—2 ğŸ“²(method_call)Ã—2 ğŸšš(move)Ã—2 ğŸ”„(mut)Ã—1 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—431 â¬…ï¸(output)Ã—12 ğŸ–¼ï¸(pat)Ã—142 ğŸ›¤ï¸(path)Ã—267 â€¼ï¸(punct)Ã—431 ğŸ“¡(receiver)Ã—2 ğŸ”—(reference)Ã—7 ğŸ§©(segments)Ã—239 â†”ï¸(spacing)Ã—431 ğŸ“œ(stmts)Ã—14 ğŸ“(str)Ã—78 ğŸŒŠ(stream)Ã—123 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—6 ğŸŸï¸(tokens)Ã—57 ğŸŒ³(tree)Ã—36 ğŸ¤(tuple)Ã—3 ğŸ”–(ty)Ã—19 ğŸ·ï¸(type)Ã—13 ğŸ·ï¸(typed)Ã—5 ğŸ·ï¸(unnamed)Ã—8 ğŸ”—(use)Ã—8 ğŸ”£(variants)Ã—2 ğŸ‘€(vis)Ã—14 | â¬œâ¬œâŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ”€ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸:::::ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ²ğŸ²ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£ğŸ“šğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œâ³â³â³â³âœ…âœ…âœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ¯ğŸ¯ğŸ¯ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸššğŸššğŸ”„ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”£ğŸ”£ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

clusters_management.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—4 ğŸ“¢(args)Ã—4 ğŸ™ï¸(arguments)Ã—4 ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—100 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—99 ğŸ†”(ident)Ã—241 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—62 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 ğŸ”„(mut)Ã—5 âš™ï¸(op)Ã—224 â¬…ï¸(output)Ã—1 ğŸ–¼ï¸(pat)Ã—5 ğŸ›¤ï¸(path)Ã—17 â€¼ï¸(punct)Ã—224 ğŸ§©(segments)Ã—12 â†”ï¸(spacing)Ã—224 ğŸ“œ(stmts)Ã—1 ğŸŒŠ(stream)Ã—98 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—2 ğŸŒ³(tree)Ã—8 ğŸ”–(ty)Ã—5 ğŸ·ï¸(type)Ã—4 ğŸ·ï¸(typed)Ã—5 ğŸ”—(use)Ã—3 ğŸ‘€(vis)Ã—1 | âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ¨ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ¦€âš™ï¸ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â¡ï¸ğŸ“šâœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸ§ ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ”—ğŸ”—ğŸ‘€

crypto_frontend_test.rs.json | â¬œ(_)Ã—4 ğŸ“¢(args)Ã—14 ğŸ¨(attrs)Ã—6 âœ…(bool)Ã—2 ğŸ“(call)Ã—6 :(colon_token)Ã—8 ğŸ“¦(content)Ã—1 ğŸš§(delimiter)Ã—6 ğŸ§®(expr)Ã—21 ğŸŒ±(fields)Ã—4 ğŸ¦€âš™ï¸(fn)Ã—5 ğŸ¦€(func)Ã—6 ğŸ‘¥(group)Ã—1 ğŸ†”(ident)Ã—83 ğŸš¦(init)Ã—13 â¡ï¸(inputs)Ã—5 ğŸ“š(items)Ã—1 ğŸ“Œ(let)Ã—13 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—14 ğŸª„(macro)Ã—5 ğŸ§ (meta)Ã—6 ğŸ”§(method)Ã—8 ğŸ“²(method_call)Ã—8 ğŸ“¦(mod)Ã—1 âš™ï¸(op)Ã—5 â¬…ï¸(output)Ã—5 ğŸ–¼ï¸(pat)Ã—13 ğŸ›¤ï¸(path)Ã—31 â€¼ï¸(punct)Ã—5 ğŸ“¡(receiver)Ã—8 ğŸ§©(segments)Ã—28 ;(semi_token)Ã—5 â†”ï¸(spacing)Ã—5 ğŸ“œ(stmts)Ã—5 ğŸ“(str)Ã—10 ğŸ›ï¸ğŸ§±(struct)Ã—4 ğŸ¨(style)Ã—6 ğŸŸï¸(tokens)Ã—6 ğŸŒ³(tree)Ã—4 ğŸ”—(use)Ã—1 | â¬œâ¬œâ¬œâ¬œğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨âœ…âœ…ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“::::::::ğŸ“¦ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸ“šğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œâœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“¦âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©;;;;;â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—

save_summary.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—3 ğŸ“¢(args)Ã—19 ğŸ™ï¸(arguments)Ã—3 ğŸ¨(attrs)Ã—2 â—(binary)Ã—1 ğŸ“(call)Ã—12 â“(cond)Ã—3 ğŸš§(delimiter)Ã—17 ğŸ“¦(elem)Ã—2 ğŸ“¦(elems)Ã—5 ğŸ§®(expr)Ã—27 ğŸ¦€âš™ï¸(fn)Ã—2 ğŸ¦€(func)Ã—12 ğŸ‘¥(group)Ã—6 ğŸ†”(ident)Ã—98 â“(if)Ã—3 ğŸ“(index)Ã—4 ğŸš¦(init)Ã—5 â¡ï¸(inputs)Ã—2 #ï¸âƒ£(int)Ã—5 ğŸ“š(items)Ã—1 ğŸ‘ˆ(left)Ã—1 ğŸ“Œ(let)Ã—6 ğŸ’¡(lit)Ã—21 ğŸª„(macro)Ã—11 ğŸ§ (meta)Ã—2 ğŸ”§(method)Ã—4 ğŸ“²(method_call)Ã—4 ğŸ”‘(name_value)Ã—2 âš™ï¸(op)Ã—20 â¬…ï¸(output)Ã—2 ğŸ–¼ï¸(pat)Ã—9 ğŸ›¤ï¸(path)Ã—47 â€¼ï¸(punct)Ã—18 ğŸ“¡(receiver)Ã—4 ğŸ”—(reference)Ã—5 ğŸ‘‰(right)Ã—1 ğŸ§©(segments)Ã—44 ;(semi_token)Ã—11 â†”ï¸(spacing)Ã—18 ğŸ“œ(stmts)Ã—2 ğŸ“(str)Ã—2 ğŸŒŠ(stream)Ã—6 ğŸ¨(style)Ã—2 â¡ï¸(then_branch)Ã—3 ğŸŸï¸(tokens)Ã—11 ğŸŒ³(tree)Ã—5 ğŸ¤(try)Ã—5 ğŸ¤(tuple)Ã—4 ğŸ—ï¸(tuple_struct)Ã—1 ğŸ”–(ty)Ã—3 ğŸ·ï¸(type)Ã—4 ğŸ·ï¸(typed)Ã—2 â–(unary)Ã—1 ğŸ”—(use)Ã—2 ğŸ’(value)Ã—2 ğŸ‘€(vis)Ã—2 | âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ¨ğŸ¨â—ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“â“â“â“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“â“â“ğŸ“ğŸ“ğŸ“ğŸ“ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£ğŸ“šğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ”‘ğŸ”‘âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©;;;;;;;;;;â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸ¨â¡ï¸â¡ï¸â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ—ï¸ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸â–ğŸ”—ğŸ”—ğŸ’ğŸ’ğŸ‘€ğŸ‘€

adaptercluster.rs.json | â¬œ(_)Ã—1 âŸ¨âŸ©(angle_bracketed)Ã—1 ğŸ“¢(args)Ã—67 ğŸ™ï¸(arguments)Ã—1 ğŸ“(assign)Ã—3 ğŸ¨(attrs)Ã—1 ğŸ(base)Ã—29 â—(binary)Ã—16 ğŸ§±(block)Ã—11 ğŸƒ(body)Ã—1 ğŸ“(call)Ã—5 ğŸ”¤(char)Ã—4 ğŸ•¸ï¸(closure)Ã—1 :(colon_token)Ã—18 â“(cond)Ã—13 ğŸš§(delimiter)Ã—24 ğŸ“¦(elem)Ã—13 ğŸ“¦(elems)Ã—10 ğŸ”„(else_branch)Ã—13 ğŸ”š(end)Ã—1 ğŸ§®(expr)Ã—80 ğŸŒ¿(field)Ã—29 ğŸŒ±(fields)Ã—6 ğŸ¦€âš™ï¸(fn)Ã—16 ğŸ¦€(func)Ã—5 ğŸ‘¥(group)Ã—15 ğŸ†”(ident)Ã—310 â“(if)Ã—13 ğŸ”¨(impl)Ã—4 ğŸ“(index)Ã—4 ğŸš¦(init)Ã—12 â¡ï¸(inputs)Ã—17 #ï¸âƒ£(int)Ã—8 ğŸ“š(items)Ã—5 ğŸ‘ˆ(left)Ã—19 ğŸ“Œ(let)Ã—18 â³(lifetime)Ã—1 ğŸ“(limits)Ã—2 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—45 ğŸª„(macro)Ã—10 ğŸ§ (meta)Ã—1 ğŸ”§(method)Ã—61 ğŸ“²(method_call)Ã—61 ğŸ”„(mut)Ã—4 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—67 â¬…ï¸(output)Ã—17 ğŸ–¼ï¸(pat)Ã—24 ğŸ›¤ï¸(path)Ã—138 â€¼ï¸(punct)Ã—51 â†”ï¸(range)Ã—2 ğŸ“¡(receiver)Ã—71 ğŸ”—(ref)Ã—7 ğŸ”—(reference)Ã—15 ğŸ‘‰(right)Ã—19 ğŸ§©(segments)Ã—134 ğŸ†”(self_ty)Ã—4 â†”ï¸(spacing)Ã—51 ğŸ”œ(start)Ã—1 ğŸ“œ(stmts)Ã—27 ğŸ“(str)Ã—15 ğŸŒŠ(stream)Ã—13 ğŸ›ï¸ğŸ§±(struct)Ã—6 ğŸ¨(style)Ã—1 â¡ï¸(then_branch)Ã—13 ğŸŸï¸(tokens)Ã—11 ğŸ§©(trait)Ã—2 ğŸŒ³(tree)Ã—10 ğŸ¤(tuple)Ã—4 ğŸ—ï¸(tuple_struct)Ã—6 ğŸ”–(ty)Ã—19 ğŸ·ï¸(type)Ã—2 ğŸ·ï¸(typed)Ã—4 ğŸ”—(use)Ã—4 ğŸ‘€(vis)Ã—18 | â¬œâŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ“ğŸ“ğŸ“ğŸ¨ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸâ—â—â—â—â—â—â—â—â—â—ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸƒğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ•¸ï¸::::::::::â“â“â“â“â“â“â“â“â“â“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”šğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“â“â“â“â“â“â“â“â“â“ğŸ”¨ğŸ”¨ğŸ”¨ğŸ”¨ğŸ“ğŸ“ğŸ“ğŸ“ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£ğŸ“šğŸ“šğŸ“šğŸ“šğŸ“šğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œâ³ğŸ“ğŸ“âœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â†”ï¸â†”ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ†”ğŸ†”ğŸ†”ğŸ†”â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ”œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸ§©ğŸ§©ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

doc_test_generator.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—8 ğŸ“¢(args)Ã—54 ğŸ™ï¸(arguments)Ã—8 ğŸ“(assign)Ã—2 ğŸ¨(attrs)Ã—2 â—(binary)Ã—5 ğŸƒ(body)Ã—7 âœ…(bool)Ã—3 ğŸ”—(bounds)Ã—2 ğŸ“(call)Ã—15 ğŸ”¤(char)Ã—7 ğŸ•¸ï¸(closure)Ã—4 :(colon_token)Ã—4 â“(cond)Ã—8 ğŸš§(delimiter)Ã—10 ğŸŒ€(dyn)Ã—2 ğŸ“¦(elem)Ã—4 ğŸ“¦(elems)Ã—3 ğŸ”„(else_branch)Ã—2 ğŸ§®(expr)Ã—50 ğŸŒ±(fields)Ã—2 ğŸ¦€âš™ï¸(fn)Ã—5 ğŸ”(for_loop)Ã—3 ğŸ¦€(func)Ã—15 ğŸ‘¥(group)Ã—1 ğŸ†”(ident)Ã—176 â“(if)Ã—8 ğŸš¦(init)Ã—15 â¡ï¸(inputs)Ã—9 #ï¸âƒ£(int)Ã—2 ğŸ“š(items)Ã—1 ğŸ‘ˆ(left)Ã—7 ğŸ“Œ(let)Ã—15 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—25 ğŸª„(macro)Ã—8 ğŸ§ (meta)Ã—2 ğŸ”§(method)Ã—31 ğŸ“²(method_call)Ã—31 ğŸ”„(mut)Ã—4 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—15 â¬…ï¸(output)Ã—9 ğŸ–¼ï¸(pat)Ã—24 ğŸ›¤ï¸(path)Ã—94 â€¼ï¸(punct)Ã—5 ğŸ“¡(receiver)Ã—31 ğŸ”—(reference)Ã—6 ğŸ‘‰(right)Ã—7 ğŸ§©(segments)Ã—90 ;(semi_token)Ã—7 â†”ï¸(spacing)Ã—5 ğŸ“œ(stmts)Ã—5 ğŸ“(str)Ã—5 ğŸŒŠ(stream)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—2 ğŸ¨(style)Ã—2 â¡ï¸(then_branch)Ã—8 ğŸŸï¸(tokens)Ã—9 ğŸ§©(trait)Ã—2 ğŸ¦‹(trait_object)Ã—2 ğŸŒ³(tree)Ã—7 ğŸ¤(try)Ã—3 ğŸ¤(tuple)Ã—3 ğŸ”–(ty)Ã—8 ğŸ·ï¸(type)Ã—11 ğŸ·ï¸(typed)Ã—4 â–(unary)Ã—5 ğŸ”—(use)Ã—3 | âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ“ğŸ“ğŸ¨ğŸ¨â—â—â—â—â—ğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒâœ…âœ…âœ…ğŸ”—ğŸ”—ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸::::â“â“â“â“â“â“â“â“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸŒ€ğŸŒ€ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ”„ğŸ”„ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ”ğŸ”ğŸ”ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“â“â“â“â“â“â“â“ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£#ï¸âƒ£ğŸ“šğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œâœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©;;;;;;;â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸŒŠğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸ§©ğŸ§©ğŸ¦‹ğŸ¦‹ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸â–â–â–â–â–ğŸ”—ğŸ”—ğŸ”—

styles.rs.json | ğŸ”’(const)Ã—1 ğŸ“¦(elem)Ã—1 ğŸ§®(expr)Ã—1 ğŸ†”(ident)Ã—2 ğŸ“š(items)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ›¤ï¸(path)Ã—1 ğŸ”—(reference)Ã—1 ğŸ§©(segments)Ã—1 ğŸ“(str)Ã—1 ğŸ”–(ty)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ”’ğŸ“¦ğŸ§®ğŸ†”ğŸ†”ğŸ“šğŸ’¡ğŸ›¤ï¸ğŸ”—ğŸ§©ğŸ“ğŸ”–ğŸ‘€

storage_entry.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—1 ğŸ“¢(args)Ã—1 ğŸ™ï¸(arguments)Ã—1 ğŸ¨(attrs)Ã—2 :(colon_token)Ã—2 ğŸš§(delimiter)Ã—1 ğŸŒ±(fields)Ã—1 ğŸ‘¥(group)Ã—1 ğŸ†”(ident)Ã—18 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”‘(name_value)Ã—1 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—2 ğŸ›¤ï¸(path)Ã—9 â€¼ï¸(punct)Ã—2 ğŸ§©(segments)Ã—5 â†”ï¸(spacing)Ã—2 ğŸ“(str)Ã—1 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—6 ğŸ”–(ty)Ã—2 ğŸ·ï¸(type)Ã—1 ğŸ”—(use)Ã—2 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—3 | âŸ¨âŸ©ğŸ“¢ğŸ™ï¸ğŸ¨ğŸ¨::ğŸš§ğŸŒ±ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šâœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”‘ğŸ·ï¸âš™ï¸âš™ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸ğŸ“ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”–ğŸ”–ğŸ·ï¸ğŸ”—ğŸ”—ğŸ’ğŸ‘€ğŸ‘€ğŸ‘€

connect_first.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—5 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—4 ğŸ†”(ident)Ã—13 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 ğŸ’¡(lit)Ã—3 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 âš™ï¸(op)Ã—4 â¬…ï¸(output)Ã—1 ğŸ›¤ï¸(path)Ã—6 â€¼ï¸(punct)Ã—4 ğŸ§©(segments)Ã—3 â†”ï¸(spacing)Ã—4 ğŸ“œ(stmts)Ã—1 ğŸŒŠ(stream)Ã—4 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—5 ğŸ”—(use)Ã—2 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ¦€âš™ï¸ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â¡ï¸ğŸ“šğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸ§ âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—ğŸ”—ğŸ‘€

main.rs.json | ğŸ“¢(args)Ã—1 ğŸ¨(attrs)Ã—1 ğŸ“(call)Ã—1 ğŸš§(delimiter)Ã—1 ğŸ§®(expr)Ã—1 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ¦€(func)Ã—1 ğŸ‘¥(group)Ã—1 ğŸ†”(ident)Ã—42 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 âœ…(list)Ã—1 ğŸ§ (meta)Ã—1 ğŸ“¦(mod)Ã—18 â¬…ï¸(output)Ã—1 ğŸ›¤ï¸(path)Ã—17 ğŸš«(restricted)Ã—3 ğŸ§©(segments)Ã—6 ;(semi)Ã—18 ğŸ“œ(stmts)Ã—1 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—19 ğŸ”—(use)Ã—8 ğŸ‘€(vis)Ã—13 | ğŸ“¢ğŸ¨ğŸ“ğŸš§ğŸ§®ğŸ¦€âš™ï¸ğŸ¦€ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â¡ï¸ğŸ“šâœ…ğŸ§ ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸš«ğŸš«ğŸš«ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©;;;;;;;;;;ğŸ“œğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

accountstate.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—2 ğŸ“¢(args)Ã—6 ğŸ™ï¸(arguments)Ã—2 ğŸ¨(attrs)Ã—1 ğŸ(base)Ã—4 :(colon_token)Ã—3 ğŸš§(delimiter)Ã—1 ğŸ“¦(elem)Ã—8 ğŸ§®(expr)Ã—4 ğŸŒ¿(field)Ã—4 ğŸŒ±(fields)Ã—1 ğŸ¦€âš™ï¸(fn)Ã—4 ğŸ‘¥(group)Ã—1 ğŸ†”(ident)Ã—38 ğŸ”¨(impl)Ã—1 â¡ï¸(inputs)Ã—4 ğŸ“š(items)Ã—2 âœ…(list)Ã—1 ğŸ§ (meta)Ã—1 ğŸ”§(method)Ã—4 ğŸ“²(method_call)Ã—4 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—2 â¬…ï¸(output)Ã—4 ğŸ›¤ï¸(path)Ã—21 â€¼ï¸(punct)Ã—2 ğŸ“¡(receiver)Ã—8 ğŸ”—(ref)Ã—4 ğŸ”—(reference)Ã—6 ğŸ§©(segments)Ã—19 ğŸ†”(self_ty)Ã—1 ğŸ°(slice)Ã—2 â†”ï¸(spacing)Ã—2 ğŸ“œ(stmts)Ã—4 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—3 ğŸ”–(ty)Ã—7 ğŸ·ï¸(type)Ã—2 ğŸ”—(use)Ã—1 ğŸ‘€(vis)Ã—8 | âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ¨ğŸğŸğŸğŸ:::ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ”¨â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸ“šğŸ“šâœ…ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ·ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ†”ğŸ°ğŸ°â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ›ï¸ğŸ§±ğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

encryption.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—4 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—3 ğŸ†”(ident)Ã—17 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 ğŸ’¡(lit)Ã—5 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 âš™ï¸(op)Ã—6 â¬…ï¸(output)Ã—1 ğŸ›¤ï¸(path)Ã—9 â€¼ï¸(punct)Ã—6 ğŸ§©(segments)Ã—3 â†”ï¸(spacing)Ã—6 ğŸ“œ(stmts)Ã—1 ğŸŒŠ(stream)Ã—3 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—8 ğŸ”—(use)Ã—2 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸš§ğŸš§ğŸš§ğŸ¦€âš™ï¸ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â¡ï¸ğŸ“šğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸ§ âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—ğŸ”—ğŸ‘€

codesnippet.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—4 ğŸ“¢(args)Ã—5 ğŸ™ï¸(arguments)Ã—4 ğŸ¨(attrs)Ã—2 ğŸ“(call)Ã—1 ğŸš§(delimiter)Ã—38 ğŸ“¦(elem)Ã—1 ğŸ“¦(elems)Ã—2 ğŸ§®(expr)Ã—3 ğŸ¦€âš™ï¸(fn)Ã—3 ğŸ¦€(func)Ã—1 ğŸ‘¥(group)Ã—35 ğŸ†”(ident)Ã—134 ğŸš¦(init)Ã—1 â¡ï¸(inputs)Ã—3 ğŸ“š(items)Ã—1 ğŸ“Œ(let)Ã—1 ğŸ’¡(lit)Ã—22 ğŸª„(macro)Ã—3 ğŸ§ (meta)Ã—2 âš™ï¸(op)Ã—53 â¬…ï¸(output)Ã—3 ğŸ–¼ï¸(pat)Ã—12 ğŸ›¤ï¸(path)Ã—35 â€¼ï¸(punct)Ã—53 ğŸ”—(reference)Ã—2 ğŸ§©(segments)Ã—28 â†”ï¸(spacing)Ã—53 ğŸ“œ(stmts)Ã—3 ğŸŒŠ(stream)Ã—35 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—3 ğŸŒ³(tree)Ã—10 ğŸ¤(tuple)Ã—2 ğŸ”–(ty)Ã—11 ğŸ·ï¸(type)Ã—4 ğŸ·ï¸(typed)Ã—11 ğŸ”—(use)Ã—3 ğŸ‘€(vis)Ã—2 | âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ¨ğŸ¨ğŸ“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸš¦â¡ï¸â¡ï¸â¡ï¸ğŸ“šğŸ“ŒğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ§ âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ”—ğŸ”—ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸ¨ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ”—ğŸ”—ğŸ‘€ğŸ‘€

use_connections.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—11 ğŸ“¢(args)Ã—97 ğŸ™ï¸(arguments)Ã—11 ğŸ¨(attrs)Ã—2 ğŸ(base)Ã—28 â—(binary)Ã—8 ğŸ§±(block)Ã—5 ğŸƒ(body)Ã—11 ğŸ”—(bounds)Ã—1 ğŸ“(call)Ã—11 ğŸ•¸ï¸(closure)Ã—11 :(colon2_token)Ã—1 :(colon_token)Ã—4 â“(cond)Ã—2 ğŸš§(delimiter)Ã—13 ğŸ“¦(elem)Ã—14 ğŸ“¦(elems)Ã—2 ğŸ§®(expr)Ã—62 ğŸŒ¿(field)Ã—28 ğŸŒ±(fields)Ã—3 ğŸ¦€âš™ï¸(fn)Ã—11 ğŸ¦€(func)Ã—11 ğŸ‘¥(group)Ã—6 ğŸ†”(ident)Ã—273 â“(if)Ã—2 ğŸ”¨(impl)Ã—1 ğŸ§©(impl_trait)Ã—1 ğŸš¦(init)Ã—19 â¡ï¸(inputs)Ã—22 ğŸ“š(items)Ã—2 ğŸ‘ˆ(left)Ã—8 ğŸ“Œ(let)Ã—19 âœ…(list)Ã—2 ğŸ’¡(lit)Ã—11 ğŸª„(macro)Ã—7 ğŸ§ (meta)Ã—2 ğŸ”§(method)Ã—74 ğŸ“²(method_call)Ã—74 ğŸšš(move)Ã—2 ğŸ”„(mut)Ã—9 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—26 â¬…ï¸(output)Ã—22 ğŸ–¼ï¸(pat)Ã—28 ğŸ›¤ï¸(path)Ã—134 â€¼ï¸(punct)Ã—17 ğŸ“¡(receiver)Ã—84 ğŸ”—(ref)Ã—10 ğŸ”—(reference)Ã—24 â†©ï¸(return)Ã—1 ğŸ‘‰(right)Ã—8 ğŸ§©(segments)Ã—126 ğŸ†”(self_ty)Ã—1 â†”ï¸(spacing)Ã—17 ğŸ“œ(stmts)Ã—16 ğŸ“(str)Ã—5 ğŸŒŠ(stream)Ã—4 ğŸ›ï¸ğŸ§±(struct)Ã—3 ğŸ¨(style)Ã—2 â¡ï¸(then_branch)Ã—2 ğŸŸï¸(tokens)Ã—9 ğŸ§©(trait)Ã—1 ğŸŒ³(tree)Ã—12 ğŸ¤(try)Ã—1 ğŸ¤(tuple)Ã—2 ğŸŸ(turbofish)Ã—1 ğŸ”–(ty)Ã—21 ğŸ·ï¸(type)Ã—15 ğŸ·ï¸(typed)Ã—7 â–(unary)Ã—1 ğŸ”—(use)Ã—4 ğŸ‘€(vis)Ã—12 | âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ¨ğŸ¨ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸâ—â—â—â—â—â—â—â—ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸ”—ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸:::::â“â“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ±ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“â“ğŸ”¨ğŸ§©ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸ“šğŸ“šğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œâœ…âœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸššğŸššğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—â†©ï¸ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ†”â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨â¡ï¸â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸ§©ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸŸğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸â–ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

query_accounts.rs.json | â¬œ(_)Ã—1 âŸ¨âŸ©(angle_bracketed)Ã—3 ğŸ“¢(args)Ã—24 ğŸ™ï¸(arguments)Ã—3 ğŸ› ï¸(arms)Ã—1 â©(async)Ã—1 ğŸ¨(attrs)Ã—1 â³(await)Ã—1 ğŸ(base)Ã—1 ğŸ§±(block)Ã—3 ğŸƒ(body)Ã—6 âœ…(bool)Ã—3 ğŸ“(call)Ã—9 ğŸ•¸ï¸(closure)Ã—4 :(colon2_token)Ã—2 â“(cond)Ã—1 ğŸš§(delimiter)Ã—45 ğŸ“¦(elems)Ã—2 ğŸ§®(expr)Ã—19 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ¦€(func)Ã—9 ğŸ‘¥(group)Ã—44 ğŸ†”(ident)Ã—161 â“(if)Ã—1 ğŸš¦(init)Ã—7 â¡ï¸(inputs)Ã—5 ğŸ“š(items)Ã—1 ğŸ“Œ(let)Ã—7 ğŸ’¡(lit)Ã—30 ğŸª„(macro)Ã—2 ğŸ¯(match)Ã—1 ğŸ§ (meta)Ã—1 ğŸ”§(method)Ã—12 ğŸ“²(method_call)Ã—12 ğŸšš(move)Ã—2 ğŸ”„(mut)Ã—4 âš™ï¸(op)Ã—75 â¬…ï¸(output)Ã—5 ğŸ–¼ï¸(pat)Ã—10 ğŸ›¤ï¸(path)Ã—41 â€¼ï¸(punct)Ã—75 ğŸ“¡(receiver)Ã—12 ğŸ”—(reference)Ã—1 â†©ï¸(return)Ã—1 ğŸ§©(segments)Ã—34 â†”ï¸(spacing)Ã—75 ğŸ“œ(stmts)Ã—5 ğŸ“(str)Ã—1 ğŸŒŠ(stream)Ã—43 ğŸ¨(style)Ã—1 â¡ï¸(then_branch)Ã—1 ğŸŸï¸(tokens)Ã—2 ğŸŒ³(tree)Ã—10 ğŸ—ï¸(tuple_struct)Ã—2 ğŸ”–(ty)Ã—1 ğŸ·ï¸(type)Ã—3 ğŸ·ï¸(typed)Ã—1 ğŸ”—(use)Ã—3 ğŸ‘€(vis)Ã—1 | â¬œâŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ› ï¸â©ğŸ¨â³ğŸğŸ§±ğŸ§±ğŸ§±ğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒâœ…âœ…âœ…ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸::â“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸ“šğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸ¯ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸššğŸššğŸ”„ğŸ”„ğŸ”„ğŸ”„âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—â†©ï¸ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ—ï¸ğŸ—ï¸ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ”—ğŸ”—ğŸ‘€

prepare_sources.rs.json | â¬œ(_)Ã—19 âŸ¨âŸ©(angle_bracketed)Ã—18 ğŸ“¢(args)Ã—289 ğŸ™ï¸(arguments)Ã—18 ğŸ› ï¸(arms)Ã—20 ğŸ”¢(array)Ã—6 ğŸ“(assign)Ã—6 ğŸ¨(attrs)Ã—1 ğŸ(base)Ã—6 â—(binary)Ã—61 ğŸ§±(block)Ã—26 ğŸƒ(body)Ã—82 âœ…(bool)Ã—9 ğŸ“(call)Ã—86 ğŸ”¤(char)Ã—6 ğŸ•¸ï¸(closure)Ã—5 :(colon2_token)Ã—5 â“(cond)Ã—51 ğŸ”’(const)Ã—1 â–¶ï¸(continue)Ã—2 ğŸš§(delimiter)Ã—136 ğŸ“¦(elem)Ã—15 ğŸ“¦(elems)Ã—314 ğŸ”„(else_branch)Ã—11 ğŸ”š(end)Ã—5 ğŸ§®(expr)Ã—486 ğŸŒ¿(field)Ã—6 ğŸ’§(float)Ã—1 ğŸ¦€âš™ï¸(fn)Ã—5 ğŸ”(for_loop)Ã—35 ğŸ¦€(func)Ã—86 ğŸ‘¥(group)Ã—51 ğŸ†”(ident)Ã—1269 â“(if)Ã—51 ğŸ“(index)Ã—22 ğŸš¦(init)Ã—107 â¡ï¸(inputs)Ã—10 #ï¸âƒ£(int)Ã—57 ğŸ“œ(item)Ã—1 ğŸ“š(items)Ã—1 ğŸ‘ˆ(left)Ã—67 ğŸ“Œ(let)Ã—112 â³(lifetime)Ã—2 ğŸ“(limits)Ã—6 ğŸ’¡(lit)Ã—1031 ğŸª„(macro)Ã—86 ğŸ¯(match)Ã—20 ğŸ§ (meta)Ã—1 ğŸ”§(method)Ã—183 ğŸ“²(method_call)Ã—183 ğŸ”„(mut)Ã—55 ğŸ”‘(name_value)Ã—1 âš™ï¸(op)Ã—364 â¬…ï¸(output)Ã—10 ( )(paren)Ã—2 ğŸ–¼ï¸(pat)Ã—209 ğŸ›¤ï¸(path)Ã—582 â€¼ï¸(punct)Ã—266 â†”ï¸(range)Ã—6 ğŸ“¡(receiver)Ã—183 ğŸ”—(reference)Ã—94 â†©ï¸(return)Ã—8 ğŸ‘‰(right)Ã—67 ğŸ§©(segments)Ã—568 ;(semi_token)Ã—23 ğŸ°(slice)Ã—1 â†”ï¸(spacing)Ã—266 ğŸ”œ(start)Ã—3 ğŸ“œ(stmts)Ã—31 ğŸ“(str)Ã—767 ğŸŒŠ(stream)Ã—50 ğŸ¨(style)Ã—1 â¡ï¸(then_branch)Ã—51 ğŸŸï¸(tokens)Ã—86 ğŸŒ³(tree)Ã—22 ğŸ¤(tuple)Ã—263 ğŸ—ï¸(tuple_struct)Ã—45 ğŸŸ(turbofish)Ã—2 ğŸ”–(ty)Ã—20 ğŸ·ï¸(type)Ã—40 ğŸ·ï¸(typed)Ã—7 â–(unary)Ã—37 ğŸ”—(use)Ã—8 ğŸ’(value)Ã—1 | â¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâ¬œâŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ”¢ğŸ”¢ğŸ”¢ğŸ”¢ğŸ”¢ğŸ”¢ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ¨ğŸğŸğŸğŸğŸğŸâ—â—â—â—â—â—â—â—â—â—ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒâœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ”¤ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸:::::â“â“â“â“â“â“â“â“â“â“ğŸ”’â–¶ï¸â–¶ï¸ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”šğŸ”šğŸ”šğŸ”šğŸ”šğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸ’§ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“â“â“â“â“â“â“â“â“â“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£ğŸ“œğŸ“šğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œâ³â³ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”‘âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸( )( )ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—â†©ï¸â†©ï¸â†©ï¸â†©ï¸â†©ï¸â†©ï¸â†©ï¸â†©ï¸ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©;;;;;;;;;;ğŸ°â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ”œğŸ”œğŸ”œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸŸğŸŸğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸â–â–â–â–â–â–â–â–â–â–ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ’

mod.rs.json | ğŸ†”(ident)Ã—3 ğŸ“š(items)Ã—1 ğŸ“¦(mod)Ã—3 ;(semi)Ã—3 ğŸ‘€(vis)Ã—3 | ğŸ†”ğŸ†”ğŸ†”ğŸ“šğŸ“¦ğŸ“¦ğŸ“¦;;;ğŸ‘€ğŸ‘€ğŸ‘€

metameme.rs.json | â¬œ(_)Ã—1 âŸ¨âŸ©(angle_bracketed)Ã—3 ğŸ“¢(args)Ã—6 ğŸ™ï¸(arguments)Ã—3 ğŸ› ï¸(arms)Ã—1 ğŸ”¢(array)Ã—4 ğŸ¨(attrs)Ã—16 ğŸ(base)Ã—1 ğŸƒ(body)Ã—3 ğŸ“(call)Ã—3 :(colon_token)Ã—12 ğŸ”’(const)Ã—4 ğŸš§(delimiter)Ã—17 ğŸ“¦(elem)Ã—9 ğŸ“¦(elems)Ã—2 ğŸ²(enum)Ã—4 ğŸ§®(expr)Ã—15 ğŸŒ¿(field)Ã—1 ğŸŒ±(fields)Ã—69 ğŸ¦€âš™ï¸(fn)Ã—7 ğŸ¦€(func)Ã—3 ğŸ‘¥(group)Ã—1 ğŸ†”(ident)Ã—214 ğŸ”¨(impl)Ã—2 â¡ï¸(inputs)Ã—7 #ï¸âƒ£(int)Ã—18 ğŸ“š(items)Ã—3 ğŸ“(len)Ã—2 â³(lifetime)Ã—3 âœ…(list)Ã—16 ğŸ’¡(lit)Ã—21 ğŸª„(macro)Ã—1 ğŸ¯(match)Ã—1 ğŸ§ (meta)Ã—16 ğŸ·ï¸(named)Ã—3 âš™ï¸(op)Ã—12 â¬…ï¸(output)Ã—7 ğŸ–¼ï¸(pat)Ã—13 ğŸ›¤ï¸(path)Ã—64 â€¼ï¸(punct)Ã—12 ğŸ“¡(receiver)Ã—2 ğŸ”—(ref)Ã—2 ğŸ”—(reference)Ã—7 ğŸ”(rest)Ã—2 ğŸ§©(segments)Ã—63 ğŸ†”(self_ty)Ã—2 â†”ï¸(spacing)Ã—12 ğŸ“œ(stmts)Ã—7 ğŸ“(str)Ã—3 ğŸ›ï¸ğŸ§±(struct)Ã—6 ğŸ¨(style)Ã—16 ğŸŸï¸(tokens)Ã—17 ğŸŒ³(tree)Ã—2 ğŸ”–(ty)Ã—21 ğŸ·ï¸(type)Ã—3 ğŸ·ï¸(typed)Ã—8 ğŸ·ï¸(unnamed)Ã—1 ğŸ”—(use)Ã—1 ğŸ”£(variants)Ã—4 ğŸ‘€(vis)Ã—16 | â¬œâŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ› ï¸ğŸ”¢ğŸ”¢ğŸ”¢ğŸ”¢ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸğŸƒğŸƒğŸƒğŸ“ğŸ“ğŸ“::::::::::ğŸ”’ğŸ”’ğŸ”’ğŸ”’ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ²ğŸ²ğŸ²ğŸ²ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ”¨ğŸ”¨â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£ğŸ“šğŸ“šğŸ“šğŸ“ğŸ“â³â³â³âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸ¯ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”ğŸ”ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ†”ğŸ†”â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ”£ğŸ”£ğŸ”£ğŸ”£ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

fileresult.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—6 ğŸ“¢(args)Ã—13 ğŸ™ï¸(arguments)Ã—6 ğŸ¨(attrs)Ã—1 ğŸ(base)Ã—2 ğŸƒ(body)Ã—1 ğŸ•¸ï¸(closure)Ã—1 :(colon2_token)Ã—1 ğŸš§(delimiter)Ã—49 ğŸ“¦(elems)Ã—2 ğŸ§®(expr)Ã—1 ğŸŒ¿(field)Ã—2 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—50 ğŸ†”(ident)Ã—151 ğŸš¦(init)Ã—1 â¡ï¸(inputs)Ã—2 ğŸ“š(items)Ã—1 ğŸ“Œ(let)Ã—1 ğŸ’¡(lit)Ã—20 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 ğŸ”§(method)Ã—6 ğŸ“²(method_call)Ã—6 âš™ï¸(op)Ã—84 â¬…ï¸(output)Ã—2 ğŸ–¼ï¸(pat)Ã—6 ğŸ›¤ï¸(path)Ã—25 â€¼ï¸(punct)Ã—84 ğŸ“¡(receiver)Ã—6 ğŸ§©(segments)Ã—18 â†”ï¸(spacing)Ã—84 ğŸ“œ(stmts)Ã—1 ğŸŒŠ(stream)Ã—48 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—9 ğŸ¤(tuple)Ã—2 ğŸŸ(turbofish)Ã—1 ğŸ”–(ty)Ã—5 ğŸ·ï¸(type)Ã—8 ğŸ·ï¸(typed)Ã—4 ğŸ”—(use)Ã—2 ğŸ‘€(vis)Ã—1 | âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ¨ğŸğŸğŸƒğŸ•¸ï¸:ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ§®ğŸŒ¿ğŸŒ¿ğŸ¦€âš™ï¸ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸš¦â¡ï¸â¡ï¸ğŸ“šğŸ“ŒğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸŸğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ”—ğŸ”—ğŸ‘€

notficationinfo.rs.json | ğŸ“¢(args)Ã—14 ğŸ“(assign)Ã—1 ğŸ¨(attrs)Ã—13 ğŸ(base)Ã—4 ğŸ”—(bounds)Ã—2 ğŸ“(call)Ã—9 :(colon_token)Ã—5 ğŸ“¦(content)Ã—1 ğŸš§(delimiter)Ã—30 ğŸ“¦(elem)Ã—4 ğŸ§®(expr)Ã—20 ğŸŒ¿(field)Ã—4 ğŸŒ±(fields)Ã—2 ğŸ¦€âš™ï¸(fn)Ã—12 ğŸ¦€(func)Ã—9 ğŸ‘¥(group)Ã—14 ğŸ†”(ident)Ã—160 ğŸ”¨(impl)Ã—1 ğŸ§©(impl_trait)Ã—2 ğŸš¦(init)Ã—10 â¡ï¸(inputs)Ã—12 #ï¸âƒ£(int)Ã—3 ğŸ“š(items)Ã—2 ğŸ‘ˆ(left)Ã—1 ğŸ“Œ(let)Ã—10 ğŸ“(limits)Ã—1 âœ…(list)Ã—6 ğŸ’¡(lit)Ã—16 ğŸª„(macro)Ã—10 ğŸ§ (meta)Ã—13 ğŸ”§(method)Ã—5 ğŸ“²(method_call)Ã—5 ğŸ“¦(mod)Ã—1 ğŸ”„(mut)Ã—1 ğŸ”‘(name_value)Ã—1 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—25 â¬…ï¸(output)Ã—12 ğŸ–¼ï¸(pat)Ã—13 ğŸ›¤ï¸(path)Ã—61 â€¼ï¸(punct)Ã—25 â†”ï¸(range)Ã—1 ğŸ“¡(receiver)Ã—9 ğŸ”—(ref)Ã—3 ğŸ”—(reference)Ã—4 ğŸ‘‰(right)Ã—1 ğŸ§©(segments)Ã—61 ğŸ†”(self_ty)Ã—1 ;(semi_token)Ã—10 â†”ï¸(spacing)Ã—25 ğŸ“œ(stmts)Ã—12 ğŸ“(str)Ã—8 ğŸŒŠ(stream)Ã—14 ğŸ›ï¸ğŸ§±(struct)Ã—2 ğŸ¨(style)Ã—13 ğŸŸï¸(tokens)Ã—16 ğŸ§©(trait)Ã—2 ğŸ”–(ty)Ã—10 ğŸ·ï¸(typed)Ã—3 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—10 | ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸğŸğŸğŸğŸ”—ğŸ”—ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“:::::ğŸ“¦ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ”¨ğŸ§©ğŸ§©ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£ğŸ“šğŸ“šğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“âœ…âœ…âœ…âœ…âœ…âœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“¦ğŸ”„ğŸ”‘ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â†”ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ†”;;;;;;;;;;â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸ§©ğŸ§©ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ’ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

mod.rs.json | ğŸ†”(ident)Ã—48 ğŸ“š(items)Ã—1 ğŸ“¦(mod)Ã—31 ğŸ›¤ï¸(path)Ã—17 ;(semi)Ã—31 ğŸŒ³(tree)Ã—34 ğŸ”—(use)Ã—17 ğŸ‘€(vis)Ã—48 | ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ“šğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸;;;;;;;;;;ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

appheader.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—3 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—2 ğŸ†”(ident)Ã—8 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 ğŸ’¡(lit)Ã—2 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 â¬…ï¸(output)Ã—1 ğŸ›¤ï¸(path)Ã—5 ğŸ§©(segments)Ã—3 ğŸ“œ(stmts)Ã—1 ğŸŒŠ(stream)Ã—2 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—3 ğŸ”—(use)Ã—1 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸš§ğŸš§ğŸ¦€âš™ï¸ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â¡ï¸ğŸ“šğŸ’¡ğŸ’¡ğŸª„ğŸ§ â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ§©ğŸ§©ğŸ§©ğŸ“œğŸŒŠğŸŒŠğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—ğŸ‘€

theme_node.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—5 ğŸ“¢(args)Ã—42 ğŸ™ï¸(arguments)Ã—5 ğŸ”¢(array)Ã—2 ğŸ“(assign)Ã—1 ğŸ¨(attrs)Ã—7 â—(binary)Ã—5 ğŸ§±(block)Ã—1 ğŸƒ(body)Ã—7 ğŸ“(call)Ã—13 ğŸ”€(cast)Ã—1 ğŸ•¸ï¸(closure)Ã—2 :(colon2_token)Ã—1 :(colon_token)Ã—5 â“(cond)Ã—1 ğŸ“¦(content)Ã—1 ğŸš§(delimiter)Ã—58 ğŸ“¦(elem)Ã—2 ğŸ“¦(elems)Ã—4 ğŸ”š(end)Ã—1 ğŸ§®(expr)Ã—50 ğŸŒ±(fields)Ã—2 ğŸ’§(float)Ã—2 ğŸ¦€âš™ï¸(fn)Ã—6 ğŸ”(for_loop)Ã—5 ğŸ¦€(func)Ã—13 ğŸ‘¥(group)Ã—38 ğŸ†”(ident)Ã—233 â“(if)Ã—1 ğŸ“(index)Ã—6 ğŸš¦(init)Ã—21 â¡ï¸(inputs)Ã—8 #ï¸âƒ£(int)Ã—11 ğŸ“š(items)Ã—1 ğŸ‘ˆ(left)Ã—6 ğŸ“(len)Ã—3 ğŸ“Œ(let)Ã—21 ğŸ“(limits)Ã—1 âœ…(list)Ã—2 ğŸ’¡(lit)Ã—92 ğŸª„(macro)Ã—20 ğŸ§ (meta)Ã—7 ğŸ”§(method)Ã—24 ğŸ“²(method_call)Ã—24 ğŸ“¦(mod)Ã—1 ğŸ”„(mut)Ã—1 ğŸ”‘(name_value)Ã—1 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—105 â¬…ï¸(output)Ã—8 ( )(paren)Ã—1 ğŸ–¼ï¸(pat)Ã—28 ğŸ›¤ï¸(path)Ã—98 â€¼ï¸(punct)Ã—99 â†”ï¸(range)Ã—1 ğŸ“¡(receiver)Ã—24 ğŸ”—(reference)Ã—4 ğŸ”(repeat)Ã—1 ğŸ‘‰(right)Ã—6 ğŸ§©(segments)Ã—91 ;(semi_token)Ã—15 â†”ï¸(spacing)Ã—99 ğŸ”œ(start)Ã—1 ğŸ“œ(stmts)Ã—7 ğŸ“(str)Ã—2 ğŸŒŠ(stream)Ã—36 ğŸ›ï¸ğŸ§±(struct)Ã—2 ğŸ¨(style)Ã—7 â¡ï¸(then_branch)Ã—1 ğŸŸï¸(tokens)Ã—22 ğŸŒ³(tree)Ã—13 ğŸ¤(tuple)Ã—4 ğŸ”–(ty)Ã—6 ğŸ·ï¸(type)Ã—5 ğŸ·ï¸(typed)Ã—2 â–(unary)Ã—1 ğŸ”—(use)Ã—6 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—5 | âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ”¢ğŸ”¢ğŸ“ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨â—â—â—â—â—ğŸ§±ğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ”€ğŸ•¸ï¸ğŸ•¸ï¸::::::â“ğŸ“¦ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ”šğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ±ğŸŒ±ğŸ’§ğŸ’§ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£#ï¸âƒ£ğŸ“šğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ“ğŸ“ğŸ“ğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“âœ…âœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“¦ğŸ”„ğŸ”‘ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸( )ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â†”ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©;;;;;;;;;;â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ”œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸â–ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ’ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

airdrop.rs.json | âŸ¨âŸ©(angle_bracketed)Ã—1 ğŸ“¢(args)Ã—9 ğŸ™ï¸(arguments)Ã—1 ğŸ“(assign)Ã—1 ğŸ¨(attrs)Ã—2 ğŸ§±(block)Ã—1 ğŸƒ(body)Ã—2 âœ…(bool)Ã—1 ğŸ“(call)Ã—3 ğŸ•¸ï¸(closure)Ã—2 â“(cond)Ã—2 ğŸš§(delimiter)Ã—53 ğŸ“¦(elems)Ã—1 ğŸ”„(else_branch)Ã—1 ğŸ§®(expr)Ã—8 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ¦€(func)Ã—3 ğŸ‘¥(group)Ã—52 ğŸ†”(ident)Ã—232 â“(if)Ã—2 ğŸš¦(init)Ã—3 â¡ï¸(inputs)Ã—3 #ï¸âƒ£(int)Ã—1 ğŸ“š(items)Ã—1 ğŸ‘ˆ(left)Ã—1 ğŸ“Œ(let)Ã—4 ğŸ’¡(lit)Ã—41 ğŸª„(macro)Ã—2 ğŸ§ (meta)Ã—2 ğŸ”§(method)Ã—5 ğŸ“²(method_call)Ã—5 ğŸ”„(mut)Ã—3 ğŸ”‘(name_value)Ã—1 âš™ï¸(op)Ã—119 â¬…ï¸(output)Ã—3 ğŸ–¼ï¸(pat)Ã—5 ğŸ›¤ï¸(path)Ã—73 â€¼ï¸(punct)Ã—118 ğŸ“¡(receiver)Ã—5 ğŸ‘‰(right)Ã—1 ğŸ§©(segments)Ã—15 â†”ï¸(spacing)Ã—118 ğŸ“œ(stmts)Ã—2 ğŸ“(str)Ã—1 ğŸŒŠ(stream)Ã—51 ğŸ¨(style)Ã—2 â¡ï¸(then_branch)Ã—2 ğŸŸï¸(tokens)Ã—2 ğŸŒ³(tree)Ã—93 ğŸ—ï¸(tuple_struct)Ã—1 ğŸ”–(ty)Ã—1 ğŸ·ï¸(type)Ã—1 ğŸ·ï¸(typed)Ã—1 â–(unary)Ã—1 ğŸ”—(use)Ã—35 ğŸ’(value)Ã—1 ğŸ‘€(vis)Ã—1 | âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ“ğŸ¨ğŸ¨ğŸ§±ğŸƒğŸƒâœ…ğŸ“ğŸ“ğŸ“ğŸ•¸ï¸ğŸ•¸ï¸â“â“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ”„ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ¦€âš™ï¸ğŸ¦€ğŸ¦€ğŸ¦€ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“â“ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£ğŸ“šğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ”„ğŸ”„ğŸ”„ğŸ”‘âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸ¨â¡ï¸â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ—ï¸ğŸ”–ğŸ·ï¸ğŸ·ï¸â–ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ’ğŸ‘€

tokenaccountresponse.rs.json | ğŸ“¢(args)Ã—4 ğŸ¨(attrs)Ã—1 ğŸ(base)Ã—17 :(colon_token)Ã—2 ğŸš§(delimiter)Ã—2 ğŸ“¦(elem)Ã—4 ğŸ§®(expr)Ã—4 ğŸŒ¿(field)Ã—17 ğŸŒ±(fields)Ã—1 ğŸ¦€âš™ï¸(fn)Ã—4 ğŸ†”(ident)Ã—51 ğŸ”¨(impl)Ã—1 â¡ï¸(inputs)Ã—4 ğŸ“š(items)Ã—2 âœ…(list)Ã—2 ğŸ’¡(lit)Ã—1 ğŸ§ (meta)Ã—2 ğŸ”§(method)Ã—4 ğŸ“²(method_call)Ã—4 ğŸ·ï¸(named)Ã—1 âš™ï¸(op)Ã—4 â¬…ï¸(output)Ã—4 ğŸ›¤ï¸(path)Ã—20 â€¼ï¸(punct)Ã—4 ğŸ“¡(receiver)Ã—8 ğŸ”—(ref)Ã—4 ğŸ”—(reference)Ã—4 ğŸ§©(segments)Ã—17 ğŸ†”(self_ty)Ã—1 â†”ï¸(spacing)Ã—4 ğŸ“œ(stmts)Ã—4 ğŸ›ï¸ğŸ§±(struct)Ã—1 ğŸ¨(style)Ã—2 ğŸŸï¸(tokens)Ã—2 ğŸŒ³(tree)Ã—5 ğŸ”–(ty)Ã—6 ğŸ”—(use)Ã—2 ğŸ‘€(vis)Ã—7 | ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ¨ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸ::ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ”¨â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸ“šğŸ“šâœ…âœ…ğŸ’¡ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ†”â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸŸï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”—ğŸ”—ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

performance_charts.rs.json | ğŸ¨(attrs)Ã—1 ğŸš§(delimiter)Ã—110 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—110 ğŸ†”(ident)Ã—212 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 ğŸ’¡(lit)Ã—189 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 âš™ï¸(op)Ã—364 â¬…ï¸(output)Ã—1 ğŸ›¤ï¸(path)Ã—6 â€¼ï¸(punct)Ã—364 ğŸ§©(segments)Ã—3 â†”ï¸(spacing)Ã—364 ğŸ“œ(stmts)Ã—1 ğŸŒŠ(stream)Ã—109 ğŸ¨(style)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—5 ğŸ”—(use)Ã—2 ğŸ‘€(vis)Ã—1 | ğŸ¨ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ¦€âš™ï¸ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â¡ï¸ğŸ“šğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸ§ âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ”—ğŸ”—ğŸ‘€

sign_message.rs.json | ğŸ“¢(args)Ã—3 ğŸ“(assign)Ã—1 ğŸ¨(attrs)Ã—1 âœ…(bool)Ã—1 â“(cond)Ã—1 ğŸš§(delimiter)Ã—30 ğŸ“¦(elems)Ã—1 ğŸ§®(expr)Ã—5 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ‘¥(group)Ã—31 ğŸ†”(ident)Ã—74 â“(if)Ã—1 ğŸš¦(init)Ã—2 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 ğŸ‘ˆ(left)Ã—1 ğŸ“Œ(let)Ã—3 ğŸ’¡(lit)Ã—15 ğŸª„(macro)Ã—1 ğŸ§ (meta)Ã—1 ğŸ”§(method)Ã—3 ğŸ“²(method_call)Ã—3 ğŸ”„(mut)Ã—1 âš™ï¸(op)Ã—37 â¬…ï¸(output)Ã—1 ğŸ–¼ï¸(pat)Ã—3 ğŸ›¤ï¸(path)Ã—13 â€¼ï¸(punct)Ã—37 ğŸ“¡(receiver)Ã—3 ğŸ‘‰(right)Ã—1 ğŸ§©(segments)Ã—7 â†”ï¸(spacing)Ã—37 ğŸ“œ(stmts)Ã—1 ğŸ“(str)Ã—1 ğŸŒŠ(stream)Ã—29 ğŸ¨(style)Ã—1 â¡ï¸(then_branch)Ã—1 ğŸŸï¸(tokens)Ã—1 ğŸŒ³(tree)Ã—9 ğŸ—ï¸(tuple_struct)Ã—1 ğŸ”—(use)Ã—3 ğŸ‘€(vis)Ã—1 | ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“ğŸ¨âœ…â“ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ¦€âš™ï¸ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“ğŸš¦ğŸš¦â¡ï¸ğŸ“šğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ”„âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ¨â¡ï¸ğŸŸï¸ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ—ï¸ğŸ”—ğŸ”—ğŸ”—ğŸ‘€

rust_parser.rs.json | â¬œ(_)Ã—4 âŸ¨âŸ©(angle_bracketed)Ã—51 ğŸ“¢(args)Ã—191 ğŸ™ï¸(arguments)Ã—52 ğŸ› ï¸(arms)Ã—6 ğŸ”¢(array)Ã—1 ğŸ“(assign)Ã—26 ğŸ¨(attrs)Ã—17 ğŸ(base)Ã—39 â—(binary)Ã—2 ğŸ§±(block)Ã—25 ğŸƒ(body)Ã—34 âœ…(bool)Ã—6 ğŸ”—(bounds)Ã—3 ğŸ“(call)Ã—31 ğŸ•¸ï¸(closure)Ã—14 :(colon_token)Ã—45 â“(cond)Ã—11 ğŸ”’(const)Ã—4 ğŸš§(delimiter)Ã—121 ğŸ“¦(elem)Ã—19 ğŸ“¦(elems)Ã—61 ğŸ”„(else_branch)Ã—4 ğŸ”š(end)Ã—1 ğŸ²(enum)Ã—1 ğŸ§®(expr)Ã—178 ğŸŒ¿(field)Ã—39 ğŸŒ±(fields)Ã—11 ğŸ¦€âš™ï¸(fn)Ã—19 ğŸ”(for_loop)Ã—3 ğŸ¦€(func)Ã—31 ğŸ”£(generics)Ã—2 ğŸ‘¥(group)Ã—96 ğŸ†”(ident)Ã—1064 â“(if)Ã—11 ğŸ”¨(impl)Ã—1 ğŸ§©(impl_trait)Ã—1 ğŸ“(index)Ã—12 ğŸš¦(init)Ã—37 â¡ï¸(inputs)Ã—34 #ï¸âƒ£(int)Ã—1 ğŸ“œ(item)Ã—1 ğŸ“š(items)Ã—2 ğŸ‘ˆ(left)Ã—28 ğŸ“Œ(let)Ã—44 â³(lifetime)Ã—13 ğŸ“(limits)Ã—1 âœ…(list)Ã—6 ğŸ’¡(lit)Ã—141 ğŸª„(macro)Ã—19 ğŸ¯(match)Ã—6 ğŸ§ (meta)Ã—17 ğŸ”§(method)Ã—109 ğŸ“²(method_call)Ã—109 ğŸšš(move)Ã—12 ğŸ”„(mut)Ã—29 ğŸ·ï¸(named)Ã—5 âš™ï¸(op)Ã—284 â¬…ï¸(output)Ã—34 âš™ï¸(params)Ã—2 ( )(parenthesized)Ã—1 ğŸ–¼ï¸(pat)Ã—109 ğŸ›¤ï¸(path)Ã—386 â€¼ï¸(punct)Ã—277 â†”ï¸(range)Ã—1 ğŸ“¡(receiver)Ã—109 ğŸ”—(reference)Ã—39 â†©ï¸(return)Ã—2 ğŸ‘‰(right)Ã—28 ğŸ§©(segments)Ã—382 ğŸ†”(self_ty)Ã—1 ğŸ°(slice)Ã—1 â†”ï¸(spacing)Ã—277 ğŸ“œ(stmts)Ã—44 ğŸ“(str)Ã—59 ğŸŒŠ(stream)Ã—96 ğŸ›ï¸ğŸ§±(struct)Ã—8 ğŸ¨(style)Ã—17 â¡ï¸(then_branch)Ã—11 ğŸŸï¸(tokens)Ã—25 ğŸ§©(trait)Ã—2 ğŸŒ³(tree)Ã—9 ğŸ¤(tuple)Ã—46 ğŸ—ï¸(tuple_struct)Ã—14 ğŸ”–(ty)Ã—75 ğŸ·ï¸(type)Ã—65 ğŸ·ï¸(typed)Ã—34 â–(unary)Ã—5 ğŸ”—(use)Ã—4 ğŸ”£(variants)Ã—1 ğŸ‘€(vis)Ã—18 | â¬œâ¬œâ¬œâ¬œâŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©âŸ¨âŸ©ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ“¢ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ™ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ› ï¸ğŸ”¢ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸğŸğŸğŸğŸğŸğŸğŸğŸğŸâ—â—ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒğŸƒâœ…âœ…âœ…âœ…âœ…âœ…ğŸ”—ğŸ”—ğŸ”—ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸ğŸ•¸ï¸::::::::::â“â“â“â“â“â“â“â“â“â“ğŸ”’ğŸ”’ğŸ”’ğŸ”’ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸš§ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ“¦ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”šğŸ²ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸ§®ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ¿ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸŒ±ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ¦€âš™ï¸ğŸ”ğŸ”ğŸ”ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ¦€ğŸ”£ğŸ”£ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ‘¥ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”ğŸ†”â“â“â“â“â“â“â“â“â“â“ğŸ”¨ğŸ§©ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦ğŸš¦â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸#ï¸âƒ£ğŸ“œğŸ“šğŸ“šğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ‘ˆğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“ŒğŸ“Œâ³â³â³â³â³â³â³â³â³â³ğŸ“âœ…âœ…âœ…âœ…âœ…âœ…ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸ’¡ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸª„ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ”§ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸ“²ğŸššğŸššğŸššğŸššğŸššğŸššğŸššğŸššğŸššğŸššğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ”„ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸âš™ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸â¬…ï¸âš™ï¸âš™ï¸( )ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ–¼ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸ğŸ›¤ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â€¼ï¸â†”ï¸ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ“¡ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”—â†©ï¸â†©ï¸ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ§©ğŸ†”ğŸ°â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸â†”ï¸ğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“œğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ›ï¸ğŸ§±ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨ğŸ¨â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸â¡ï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸŸï¸ğŸ§©ğŸ§©ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸŒ³ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ¤ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ—ï¸ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ”–ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸ğŸ·ï¸â–â–â–â–â–ğŸ”—ğŸ”—ğŸ”—ğŸ”—ğŸ”£ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€ğŸ‘€

doc_processor.rs.json | ğŸš§(delimiter)Ã—1 ğŸ¦€âš™ï¸(fn)Ã—1 ğŸ†”(ident)Ã—2 â¡ï¸(inputs)Ã—1 ğŸ“š(items)Ã—1 ğŸ’¡(lit)Ã—1 ğŸª„(macro)Ã—1 â¬…ï¸(output)Ã—1 ğŸ›¤ï¸(path)Ã—1 ğŸ§©(segments)Ã—1 ;(semi_token)Ã—1 ğŸ“œ(stmts)Ã—1 ğŸŸï¸(tokens)Ã—1 | ğŸš§ğŸ¦€âš™ï¸ğŸ†”ğŸ†”â¡ï¸ğŸ“šğŸ’¡ğŸª„â¬…ï¸ğŸ›¤ï¸ğŸ§©;ğŸ“œğŸŸï¸

emojis.rs.json | â¬œ(_)Ã—6 âŸ¨âŸ©(angle_bracketed)Ã—18 ğŸ“¢(args)Ã—43 ğŸ™ï¸(arguments)Ã—18 ğŸ› ï¸(arms)Ã—3 ğŸ¨(a



You've provided a substantial list of .rs.json file summaries, each detailing the counts of various programming constructs using your emoji notation. This is a rich dataset for analyzing the "topological objects" that these code files represent!

Let's break down the different structures you've shared.

Analysis of Code "Topological Objects"
It's clear that you're using these summaries to categorize and understand the "shape" and complexity of different Rust code files. We can see a few distinct patterns emerging.

The "Default" or "Simple Struct" Object
A significant number of your files share an identical, relatively simple structure. This structure is characterized by:

ğŸ¨(attrs)Ã—1

ğŸš§(delimiter)Ã—1

ğŸŒ±(fields)Ã—1

ğŸ†”(ident)Ã—6

ğŸ“š(items)Ã—1

âœ…(list)Ã—1

ğŸ’¡(lit)Ã—1

ğŸ§ (meta)Ã—2

ğŸ”‘(name_value)Ã—1

ğŸ›¤ï¸(path)Ã—3

ğŸ§©(segments)Ã—2

ğŸ“(str)Ã—1

ğŸ›ï¸ğŸ§±(struct)Ã—1

ğŸ¨(style)Ã—2

ğŸŸï¸(tokens)Ã—1

ğŸŒ³(tree)Ã—2

ğŸ”—(use)Ã—1

ğŸ’(value)Ã—1

ğŸ‘€(vis)Ã—1

The files that exhibit this identical structure include:

test_components.rs.json (This one starts this way, but cuts off, so it's hard to be certain it only contains these, but the beginning matches the pattern)

vendor_hyperutil_src_client_legacy_connect_proxy_socks.rs.json

vendor_rustix_src_backend_linux_raw_mm.rs.json

vendor_borsh_docs_criterion_de_account_bincode_report.rs.json

vendor_unicase_github_workflows.rs.json

vendor_walkdir_walkdirlist.rs.json

vendor_formats.rs.json

vendor_ahocorasick_benchmarks_regexes.rs.json

vendor_icu4x_provider_source_tests_data_cldr_cldrcalbuddhistfull_main_srLatn.rs.json

vendor_icu4x_provider_source_data_debug_datetime_patterns_date_coptic_v1_m0de.rs.json

vendor_windowsrs_crates_tests_misc_sys_tests.rs.json

vendor_borsh_docs_criterion_ser_header_speedy_idx3size108473_report_both.rs.json

vendor_borsh_docs_criterion_de_transaction_cbor_idx7size371_report.rs.json

vendor_hashes_fsb_tests.rs.json

vendor_icu4x_components_locale_src_fallback.rs.json

vendor_manganis_testpackage.rs.json

vendor_vcpkgrs_testdata_nostatus_installed_vcpkg_updates.rs.json

vendor_icu4x_provider_source_data_debug_unit_ids_v1_permille.rs.json

This strongly suggests that these files might represent:

Very simple data structures, perhaps single-field structs used for basic data passing or configuration.

Placeholder or minimal Rust files generated by a tool.

AST representations of highly uniform boilerplate code.

From a topological perspective, all these files represent the exact same "object," having an identical set and count of their constituent parts.

Small, Specialized Objects
We also see some files that are simple but slightly more varied:

mod.rs.json (first one): ğŸ†”(ident)Ã—3, ğŸ“š(items)Ã—1, ğŸ“¦(mod)Ã—3, ;(semi)Ã—3, ğŸ‘€(vis)Ã—3. This describes a very basic module declaration with multiple sub-modules. It's a distinct, minimal topological object.

styles.rs.json: ğŸ”’(const)Ã—1, ğŸ“¦(elem)Ã—1, ğŸ§®(expr)Ã—1, ğŸ†”(ident)Ã—2, ğŸ“š(items)Ã—1, ğŸ’¡(lit)Ã—1, ğŸ›¤ï¸(path)Ã—1, ğŸ”—(reference)Ã—1, ğŸ§©(segments)Ã—1, ğŸ“(str)Ã—1, ğŸ”–(ty)Ã—1, ğŸ‘€(vis)Ã—1. This looks like a constant definition with a specific type and value, another distinct small object.

doc_processor.rs.json: ğŸš§(delimiter)Ã—1, ğŸ¦€âš™ï¸(fn)Ã—1, ğŸ†”(ident)Ã—2, â¡ï¸(inputs)Ã—1, ğŸ“š(items)Ã—1, ğŸ’¡(lit)Ã—1, ğŸª„(macro)Ã—1, â¬…ï¸(output)Ã—1, ğŸ›¤ï¸(path)Ã—1, ğŸ§©(segments)Ã—1, ;(semi_token)Ã—1, ğŸ“œ(stmts)Ã—1, ğŸŸï¸(tokens)Ã—1. This looks like a very basic function definition, possibly a one-liner, indicating a simple functional "object."

Moderately Complex Objects
Several files fall into a "medium complexity" range, showing more diversity and higher counts of constructs, indicating more elaborate code:

lean.rs.json: As noted before, this one is significantly more complex than the "default" struct, with functions, macros, and more identifiers.

clusters_management.rs.json: Features like ğŸ†”(ident)Ã—241, âš™ï¸(op)Ã—224, ğŸš§(delimiter)Ã—100, ğŸ‘¥(group)Ã—99, and ğŸ’¡(lit)Ã—62 suggest a moderately sized file with a single function, likely involving a good amount of logic and string/literal manipulation.

crypto_frontend_test.rs.json: With multiple functions (ğŸ¦€âš™ï¸(fn)Ã—5), ğŸ†”(ident)Ã—83, and ğŸ’¡(lit)Ã—14, this indicates a test file with several test cases or helper functions.

save_summary.rs.json: Shows multiple calls (ğŸ“(call)Ã—12), âš™ï¸(op)Ã—20, and ğŸª„(macro)Ã—11, suggesting a file that performs several operations and uses macros extensively.

connect_first.rs.json: Similar to lean.rs.json but slightly less complex.

main.rs.json: Features ğŸ“¦(mod)Ã—18 and ğŸ†”(ident)Ã—42, indicating a file that primarily defines or re-exports many modules. This forms a very hierarchical "topological object."

accountstate.rs.json: With ğŸ†”(ident)Ã—38, ğŸ”§(method)Ã—4, ğŸ“²(method_call)Ã—4, it implies a struct with methods, representing an object-oriented "object."

encryption.rs.json: Similar to connect_first.rs.json in complexity.

codesnippet.rs.json: Shows multiple functions (ğŸ¦€âš™ï¸(fn)Ã—3), a fair number of identifiers (ğŸ†”(ident)Ã—134), and high âš™ï¸(op)Ã—53 and ğŸš§(delimiter)Ã—38 counts, indicating a piece of code with several functions and intricate logic.

storage_entry.rs.json: More identifiers and paths than the simple struct, but still relatively small.

tokenaccountresponse.rs.json: Similar to accountstate.rs.json with a struct and methods.

performance_charts.rs.json: Dominated by ğŸ’¡(lit)Ã—189, âš™ï¸(op)Ã—364, â€¼ï¸(punct)Ã—364, â†”ï¸(spacing)Ã—364, and ğŸš§(delimiter)Ã—110, this strongly suggests a file primarily composed of data, perhaps for generating charts or defining constants, rather than complex logic. A very "data-dense" topological object.

sign_message.rs.json: Features ğŸ†”(ident)Ã—74, âš™ï¸(op)Ã—37, ğŸª„(macro)Ã—1, indicating some logic and macro use.

fileresult.rs.json: A file with ğŸ†”(ident)Ã—151, âš™ï¸(op)Ã—84, and ğŸš§(delimiter)Ã—49, suggesting a more involved file.

notficationinfo.rs.json: Similar to fileresult.rs.json in its general complexity level.

appheader.rs.json: A simpler function definition.

Large and Complex Objects
Finally, we have prepare_sources.rs.json and rust_parser.rs.json which stand out for their sheer scale and diversity of constructs:

prepare_sources.rs.json: This is a massive file with extremely high counts across almost all categories: ğŸ“¢(args)Ã—289, ğŸ†”(ident)Ã—1269, ğŸ’¡(lit)Ã—1031, âš™ï¸(op)Ã—364, â€¼ï¸(punct)Ã—266, ğŸ“(str)Ã—767, ğŸ“(call)Ã—86, ğŸ”§(method)Ã—183, ğŸ“²(method_call)Ã—183, ğŸ”(for_loop)Ã—35, â“(cond)Ã—51, ğŸ¤(tuple)Ã—263, ğŸ—ï¸(tuple_struct)Ã—45, etc. This file represents a highly complex and probably extensive codebase, likely performing a large number of operations, transformations, or data processing. This is a very large and intricate "topological object."

rust_parser.rs.json: This file is similarly complex to prepare_sources.rs.json, with high counts for many constructs like ğŸ†”(ident)Ã—1064, ğŸ“¢(args)Ã—191, âš™ï¸(op)Ã—284, â€¼ï¸(punct)Ã—277, ğŸ›¤ï¸(path)Ã—386, ğŸ§±(block)Ã—25, ğŸ”—(reference)Ã—39, ğŸ“œ(stmts)Ã—44, etc. As its name suggests, a Rust parser would naturally be a very large and complex piece of code, representing a highly connected and intricate topological object.

Your Word-to-Emoji Mappings
You've also included several word-to-emoji mappings, like 6ï¸âƒ£Ã—1, â±ï¸Ã—1, ğŸ“–Ã—1, ğŸ“±Ã—1, ğŸŒÃ—2, ğŸŒÃ—1, â°Ã—1, â›ªÃ—1, 3ï¸âƒ£Ã—1, 7ï¸âƒ£Ã—1, ğŸ“¦Ã—1, âœ…Ã—1. These appear to be separate from the file structure summaries and likely serve as counts for other aspects of your analysis or simply as a legend for your emoji use.

Imagining the Topological Objects
By breaking down the files in this way, we can indeed "imagine" the topological objects:

The "Simple Structs" are like tiny, uniform building blocks, perhaps very similar in shape and internal connections.

The "Small Specialized Objects" are slightly more unique, perhaps a single function or a simple module structure, forming distinct but still relatively small shapes.

The "Moderately Complex Objects" are more varied, like different types of small machines, each with unique internal workings (functions, methods, control flow).

The "Large and Complex Objects" like prepare_sources.rs.json and rust_parser.rs.json are massive, highly interconnected networks of logic, data, and interactions, representing very dense and intricate topological structures.

This method provides a fascinating quantitative way to compare and classify code structures. What further insights are you hoping to gain from this topological perspective of code?







so you can write some rules in rust to classify these structures, they are from syn . use walkdir::WalkDir;

use std::fs;

use std::collections::HashMap;

use solfunmeme_dioxus::core::code_analyzer::CodeAnalyzer;

use std::path::Path;

use std::time::{SystemTime, UNIX_EPOCH};

use std::collections::BTreeMap;

use regex::Regex;



/**

idea : lets build a mini compiler right here

first filter out only rust files.

refactor this code into parts.

read the source

parse to ast

embed source into vector

report and identify duplicates



construction of functions to match struture of the code and

reporting on the matches

analysis of the of the statistics of the matches

construction of new functions based on the statistics

construction of new functions based on the matches

construction of new functions based on the analysis

construction of new functions based on the reporting

construction of new functions based on the extraction

construction of new functions based on the mathematical model

construction of new functions based on the export

a recursive feedback loop using LLMS and statistics to dynamically create new functions and models in real time.





extraction of terms from identifiers

extraction of relcationships between terms

creation of mathematical mmodel



export data for gui (reduce the size)



Â */



// --- AST Node Type Emoji Mapping (updated & deduplicated) ---

const EMOJI_TYPE_MAP: &[(&str, &str, &str)] = &[

Â  Â  // Rust Core

Â  Â  ("fn", "ğŸ¦€âš™ï¸", "Rust Core"),

Â  Â  ("struct", "ğŸ›ï¸ğŸ§±", "Rust Core"),

Â  Â  ("enum", "ğŸ²", "Rust Core"),

Â  Â  ("mod", "ğŸ“¦", "Rust Core"),

Â  Â  ("use", "ğŸ”—", "Rust Core"),

Â  Â  ("impl", "ğŸ”¨", "Rust Core"),

Â  Â  ("trait", "ğŸ§©", "Rust Core"),

Â  Â  ("const", "ğŸ”’", "Rust Core"),

Â  Â  ("static", "ğŸª¨", "Rust Core"),

Â  Â  ("type", "ğŸ·ï¸", "Rust Core"),

Â  Â  ("ident", "ğŸ†”", "Rust Core"),

Â  Â  ("attrs", "ğŸ¨", "Rust Core"),

Â  Â  ("fields", "ğŸŒ±", "Rust Core"),

Â  Â  ("meta", "ğŸ§ ", "Rust Core"),

Â  Â  ("path", "ğŸ›¤ï¸", "Rust Core"),

Â  Â  ("lit", "ğŸ’¡", "Rust Core"),

Â  Â  ("tokens", "ğŸŸï¸", "Rust Core"),

Â  Â  ("expr", "ğŸ§®", "Rust Core"),

Â  Â  ("block", "ğŸ§±", "Rust Core"),

Â  Â  ("call", "ğŸ“", "Rust Core"),

Â  Â  ("method", "ğŸ”§", "Rust Core"),

Â  Â  ("macro", "ğŸª„", "Rust Core"),

Â  Â  ("trait_object", "ğŸ¦‹", "Rust Core"),

Â  Â  ("item", "ğŸ“œ", "Rust Core"),

Â  Â  ("items", "ğŸ“š", "Rust Core"),

Â  Â  ("field", "ğŸŒ¿", "Rust Core"),

Â  Â  ("inputs", "â¡ï¸", "Rust Core"),

Â  Â  ("output", "â¬…ï¸", "Rust Core"),

Â  Â  ("receiver", "ğŸ“¡", "Rust Core"),

Â  Â  ("generics", "ğŸ”£", "Rust Core"),

Â  Â  ("lifetime", "â³", "Rust Core"),

Â  Â  ("where_clause", "â“", "Rust Core"),

Â  Â  ("tuple", "ğŸ¤", "Rust Core"),

Â  Â  ("tuple_struct", "ğŸ—ï¸", "Rust Core"),

Â  Â  ("array", "ğŸ”¢", "Rust Core"),

Â  Â  ("int", "#ï¸âƒ£", "Rust Core"),

Â  Â  ("float", "ğŸ’§", "Rust Core"),

Â  Â  ("bool", "âœ…", "Rust Core"),

Â  Â  ("char", "ğŸ”¤", "Rust Core"),

Â  Â  ("str", "ğŸ“", "Rust Core"),

Â  Â  ("closure", "ğŸ•¸ï¸", "Rust Core"),

Â  Â  ("let", "ğŸ“Œ", "Rust Core"),

Â  Â  ("match", "ğŸ¯", "Rust Core"),

Â  Â  ("if", "â“", "Rust Core"),

Â  Â  ("else_branch", "ğŸ”„", "Rust Core"),

Â  Â  ("then_branch", "â¡ï¸", "Rust Core"),

Â  Â  ("for_loop", "ğŸ”", "Rust Core"),

Â  Â  ("while", "ğŸ”‚", "Rust Core"),

Â  Â  ("loop", "â™¾ï¸", "Rust Core"),

Â  Â  ("return", "â†©ï¸", "Rust Core"),

Â  Â  ("break", "â›”", "Rust Core"),

Â  Â  ("continue", "â–¶ï¸", "Rust Core"),

Â  Â  ("assign", "ğŸ“", "Rust Core"),

Â  Â  ("op", "âš™ï¸", "Rust Core"),

Â  Â  ("unary", "â–", "Rust Core"),

Â  Â  ("binary", "â—", "Rust Core"),

Â  Â  ("cast", "ğŸ”€", "Rust Core"),

Â  Â  ("index", "ğŸ“", "Rust Core"),

Â  Â  ("range", "â†”ï¸", "Rust Core"),

Â  Â  ("slice", "ğŸ°", "Rust Core"),

Â  Â  ("macro_rules", "ğŸ“", "Rust Core"),

Â  Â  ("group", "ğŸ‘¥", "Rust Core"),

Â  Â  ("delim", "ğŸš§", "Rust Core"),

Â  Â  ("punct", "â€¼ï¸", "Rust Core"),

Â  Â  ("paren", "( )", "Rust Core"),

Â  Â  ("bracket", "[ ]", "Rust Core"),

Â  Â  ("brace", "{ }", "Rust Core"),

Â  Â  ("attr", "ğŸ–¼ï¸", "Rust Core"),

Â  Â  ("name_value", "ğŸ”‘", "Rust Core"),

Â  Â  ("value", "ğŸ’", "Rust Core"),

Â  Â  ("style", "ğŸ¨", "Rust Core"),

Â  Â  ("method_call", "ğŸ“²", "Rust Core"),

Â  Â  ("dyn", "ğŸŒ€", "Rust Core"),

Â  Â  ("mut", "ğŸ”„", "Rust Core"),

Â  Â  ("ref", "ğŸ”—", "Rust Core"),

Â  Â  ("self_ty", "ğŸ†”", "Rust Core"),

Â  Â  ("super", "ğŸŒŸ", "Rust Core"),

Â  Â  ("crate", "ğŸšš", "Rust Core"),

Â  Â  ("macro_input", "ğŸ“¥", "Rust Core"),

Â  Â  ("macro_output", "ğŸ“¦", "Rust Core"),

Â  Â  ("params", "âš™ï¸", "Rust Core"),

Â  Â  ("args", "ğŸ“¢", "Rust Core"),

Â  Â  ("arguments", "ğŸ™ï¸", "Rust Core"),

Â  Â  ("arm", "ğŸ›¡ï¸", "Rust Core"),

Â  Â  ("arms", "ğŸ› ï¸", "Rust Core"),

Â  Â  ("variant", "ğŸ­", "Rust Core"),

Â  Â  ("variants", "ğŸ”£", "Rust Core"),

Â  Â  ("fields_named", "ğŸ·ï¸", "Rust Core"),

Â  Â  ("fields_unnamed", "ğŸŒ¿", "Rust Core"),

Â  Â  ("pat", "ğŸ–¼ï¸", "Rust Core"),

Â  Â  ("stmt", "ğŸ–‹ï¸", "Rust Core"),

Â  Â  ("stmts", "ğŸ“œ", "Rust Core"),

Â  Â  ("ty", "ğŸ”–", "Rust Core"),

Â  Â  ("bound", "â›“ï¸", "Rust Core"),

Â  Â  ("bounds", "ğŸ”—", "Rust Core"),

Â  Â  ("vis", "ğŸ‘€", "Rust Core"),

Â  Â  ("list", "âœ…", "Rust Core"),

Â  Â  ("token", "ğŸŸï¸", "Rust Core"),

Â  Â  ("tree", "ğŸŒ³", "Rust Core"),

Â  Â  ("segment", "ğŸ§©", "Rust Core"),

Â  Â  ("segments", "ğŸ§©", "Rust Core"),

Â  Â  ("assoc_type", "ğŸ”—", "Rust Core"),

Â  Â  ("async", "â©", "Rust Core"),

Â  Â  ("await", "â³", "Rust Core"),

Â  Â  ("base", "ğŸ", "Rust Core"),

Â  Â  ("body", "ğŸƒ", "Rust Core"),

Â  Â  ("colon_token", ":", "Rust Core"),

Â  Â  ("delimiter", "ğŸš§", "Rust Core"),

Â  Â  ("angle_bracketed", "âŸ¨âŸ©", "Rust Core"),

Â  Â  ("cond", "â“", "Rust Core"),

Â  Â  ("func", "ğŸ¦€", "Rust Core"),

Â  Â  ("init", "ğŸš¦", "Rust Core"),

Â  Â  ("right", "ğŸ‘‰", "Rust Core"),

Â  Â  ("semi", ";", "Rust Core"),

Â  Â  ("semi_token", ";", "Rust Core"),

Â  Â  ("spacing", "â†”ï¸", "Rust Core"),

Â  Â  ("start", "ğŸ”œ", "Rust Core"),

Â  Â  ("stream", "ğŸŒŠ", "Rust Core"),

Â  Â  ("try", "ğŸ¤", "Rust Core"),

Â  Â  ("bare_fn", "ğŸ¦€", "Rust Core"),

Â  Â  ("bounded_ty", "ğŸ“", "Rust Core"),

Â  Â  ("byte_str", "ğŸ’¾", "Rust Core"),

Â  Â  ("cases", "ğŸ­", "Rust Core"),

Â  Â  ("dot2_token", "â€¢", "Rust Core"),

Â  Â  ("elem", "ğŸ“¦", "Rust Core"),

Â  Â  ("elems", "ğŸ“¦", "Rust Core"),

Â  Â  ("end", "ğŸ”š", "Rust Core"),

Â  Â  ("impl_trait", "ğŸ§©", "Rust Core"),

Â  Â  ("left", "ğŸ‘ˆ", "Rust Core"),

Â  Â  ("len", "ğŸ“", "Rust Core"),

Â  Â  ("limits", "ğŸ“", "Rust Core"),

Â  Â  ("move", "ğŸšš", "Rust Core"),

Â  Â  ("named", "ğŸ·ï¸", "Rust Core"),

Â  Â  ("or", "ğŸ”€", "Rust Core"),

Â  Â  ("parenthesized", "( )", "Rust Core"),

Â  Â  ("reference", "ğŸ”—", "Rust Core"),

Â  Â  ("rename", "ğŸ“", "Rust Core"),

Â  Â  ("repeat", "ğŸ”", "Rust Core"),

Â  Â  ("rest", "ğŸ”", "Rust Core"),

Â  Â  ("restricted", "ğŸš«", "Rust Core"),

Â  Â  ("turbofish", "ğŸŸ", "Rust Core"),

Â  Â  ("typed", "ğŸ·ï¸", "Rust Core"),

Â  Â  ("unnamed", "ğŸ·ï¸", "Rust Core"),

Â  Â  ("unsafe", "â˜¢ï¸", "Rust Core"),

Â  Â  // Web/CSS

Â  Â  ("px", "ğŸ“", "Web/CSS"), ("deg", "ğŸ§­", "Web/CSS"), ("em", "ğŸ” ", "Web/CSS"), ("rem", "ğŸ”¡", "Web/CSS"), ("vh", "ğŸ“", "Web/CSS"), ("vw", "ğŸ“", "Web/CSS"), ("s", "â±ï¸", "Web/CSS"), ("ms", "â²ï¸", "Web/CSS"),

Â  Â  ("animation", "ğŸï¸", "Web/CSS"), ("transition", "ğŸ”„", "Web/CSS"), ("absolute", "ğŸ“", "Web/CSS"), ("align", "ğŸ“", "Web/CSS"), ("app", "ğŸ“±", "Web/CSS"), ("app_state", "ğŸ—„ï¸", "Web/CSS"), ("accessibility", "â™¿", "Web/CSS"),

Â  Â  ("adapter", "ğŸ”Œ", "Web/CSS"), ("actions", "ğŸ¬", "Web/CSS"), ("action", "ğŸ¬", "Web/CSS"), ("active", "ğŸ”¥", "Web/CSS"),

Â  Â  // Crypto/Security/Systems

Â  Â  ("aead", "ğŸ”’", "Crypto"), ("aeads", "ğŸ”’", "Crypto"), ("aes", "ğŸ”‘", "Crypto"), ("argon2", "ğŸ§‚", "Crypto"), ("arc", "ğŸ§²", "Crypto"), ("addr2line", "ğŸ“", "Crypto"), ("aarch64", "ğŸ“¦", "Crypto"), ("amd64", "ğŸ’»", "Crypto"), ("armv8", "ğŸ’ª", "Crypto"),

Â  Â  ("crypto", "ğŸ”’", "Crypto"), ("curve25519", "â°", "Crypto"), ("ed25519", "ğŸ“", "Crypto"), ("elliptic", "â°", "Crypto"), ("fiat", "ğŸ’µ", "Crypto"), ("cbor", "ğŸ“¦", "Crypto"),

Â  Â  // Project-specific

Â  Â  ("agave", "ğŸŒµ", "Project-Specific"), ("helius", "ğŸŒ", "Project-Specific"),

Â  Â  // Internationalization

Â  Â  ("icu4x", "ğŸŒ", "Internationalization"), ("cldr", "ğŸŒ", "Internationalization"), ("chinese", "ğŸ€„", "Internationalization"), ("hebrew", "âœ¡ï¸", "Internationalization"), ("coptic", "â›ª", "Internationalization"), ("ethiopic", "ğŸŒ„", "Internationalization"), ("calendar", "ğŸ“…", "Internationalization"), ("datetime", "â°", "Internationalization"),

Â  Â  // Testing/Benchmarking

Â  Â  ("criterion", "â±ï¸", "Testing"), ("benches", "ğŸ‹ï¸", "Testing"), ("fuzz", "ğŸ§ª", "Testing"), ("examples", "ğŸ“š", "Testing"), ("docs", "ğŸ“–", "Testing"),

Â  Â  // Misc/General

Â  Â  ("algebra", "â—", "General"), ("analysis", "ğŸ”", "General"), ("analyze", "ğŸ”¬", "General"), ("account", "ğŸ‘¤", "General"), ("accounts", "ğŸ‘¥", "General"),

Â  Â  // Suffixes for versioning/hashes

Â  Â  ("zm", "ğŸ§¬", "Versioning"), ("h", "â³", "Versioning"), ("v", "ğŸ”¢", "Versioning"),

Â  Â  // Color codes (hex)

Â  Â  ("ff", "ğŸ¨", "Color"), ("00", "âš«", "Color"), ("ffffff", "â¬œ", "Color"), ("000000", "â¬›", "Color"),

Â  Â  // Numbers (for fun)

Â  Â  ("0", "0ï¸âƒ£", "Numbers"), ("1", "1ï¸âƒ£", "Numbers"), ("2", "2ï¸âƒ£", "Numbers"), ("3", "3ï¸âƒ£", "Numbers"), ("4", "4ï¸âƒ£", "Numbers"), ("5", "5ï¸âƒ£", "Numbers"), ("6", "6ï¸âƒ£", "Numbers"), ("7", "7ï¸âƒ£", "Numbers"), ("8", "8ï¸âƒ£", "Numbers"), ("9", "9ï¸âƒ£", "Numbers"), ("10", "ğŸ”Ÿ", "Numbers"), ("100", "ğŸ’¯", "Numbers"), ("255", "ğŸŸ§", "Numbers"),

Â  Â  // Emoji codepoints

Â  Â  ("1f3a8", "ğŸ¨", "Emoji"), ("1f4dd", "ğŸ“", "Emoji"), ("1f680", "ğŸš€", "Emoji"), ("1f4a9", "ğŸ’©", "Emoji"),

Â  Â  // Heuristic/structural

Â  Â  ("byte", "ğŸ’¾", "Numbers"), ("parenthes", "( )", "Rust Core"), ("case", "ğŸ­", "Rust Core"), ("dot", "â€¢", "General"), ("colon", ":", "General"), ("bounded", "ğŸ“", "General"),

Â  Â  ("_", "â¬œ", "Rust Core"), ("colon2_token", ":", "Rust Core"), ("cond", "â“", "Rust Core"), ("content", "ğŸ“¦", "General"), ("if", "â“", "Rust Core"), ("where_clause", "ğŸ“œ", "Rust Core"),

];



fn emoji_for_type(ty: &str) -> (&'static str, &'static str) {

Â  Â  for &(name, emoji, category) in EMOJI_TYPE_MAP {

Â  Â  Â  Â  if ty == name {

Â  Â  Â  Â  Â  Â  return (emoji, category);

Â  Â  Â  Â  }

Â  Â  }

Â  Â  ("â“ğŸ¤·", "Uncategorized")

}



fn extract_string_literals(value: &serde_json::Value, out: &mut Vec<String>) {

Â  Â  match value {

Â  Â  Â  Â  serde_json::Value::Object(map) => {

Â  Â  Â  Â  Â  Â  for (k, v) in map.iter() {

Â  Â  Â  Â  Â  Â  Â  Â  // Look for string literal keys

Â  Â  Â  Â  Â  Â  Â  Â  if (k == "lit" || k == "str") && v.is_string() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if let Some(s) = v.as_str() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  out.push(s.to_string());

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  extract_string_literals(v, out);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  },

Â  Â  Â  Â  serde_json::Value::Array(arr) => {

Â  Â  Â  Â  Â  Â  for v in arr {

Â  Â  Â  Â  Â  Â  Â  Â  extract_string_literals(v, out);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  },

Â  Â  Â  Â  _ => {}

Â  Â  }

}



fn split_words(s: &str) -> Vec<String> {

Â  Â  // Split on whitespace, punctuation, underscores

Â  Â  let mut words = Vec::new();

Â  Â  let _re = Regex::new(r"[A-Za-z0-9]+_").unwrap(); // dummy, not used for splitting

Â  Â  for part in s.split(|c: char| !c.is_alphanumeric() && c != '_') {

Â  Â  Â  Â  if part.is_empty() { continue; }

Â  Â  Â  Â  // Manually split CamelCase

Â  Â  Â  Â  let mut last = 0;

Â  Â  Â  Â  let chars: Vec<char> = part.chars().collect();

Â  Â  Â  Â  for i in 1..chars.len() {

Â  Â  Â  Â  Â  Â  if chars[i].is_uppercase() && chars[i - 1].is_lowercase() {

Â  Â  Â  Â  Â  Â  Â  Â  words.push(chars[last..i].iter().collect::<String>().to_lowercase());

Â  Â  Â  Â  Â  Â  Â  Â  last = i;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  if last < chars.len() {

Â  Â  Â  Â  Â  Â  words.push(chars[last..].iter().collect::<String>().to_lowercase());

Â  Â  Â  Â  }

Â  Â  }

Â  Â  words

}



fn main() {

Â  Â  // Print emoji mapping at startup

Â  Â  // println!("=== AST Node Type Emoji Mapping ===");

Â  Â  // for (name, emoji, category) in EMOJI_TYPE_MAP {

Â  Â  // Â  Â  println!("{:>10}: {} ({})", name, emoji, category);

Â  Â  // }

Â  Â  // println!("");



Â  Â  // 1. Discover all Rust files

Â  Â  let mut files = HashMap::new();

Â  Â  let mut file_count = 0;

Â  Â  for entry in WalkDir::new("src").into_iter().filter_map(Result::ok) {

Â  Â  Â  Â  if entry.file_type().is_file() && entry.path().extension().map_or(false, |e| e == "rs") {

Â  Â  Â  Â  Â  Â  let path = entry.path().to_string_lossy().to_string();

Â  Â  Â  Â  Â  Â  match fs::read_to_string(entry.path()) {

Â  Â  Â  Â  Â  Â  Â  Â  Ok(content) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  files.insert(path, content);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_count += 1;

Â  Â  Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  println!("[ERROR: could not read file: {}]", e);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â  if files.is_empty() {

Â  Â  Â  Â  println!("[WARN] No Rust files found. Exiting.");

Â  Â  Â  Â  return;

Â  Â  }



Â  Â  // 2. Create HF dataset structure early

Â  Â  println!("\n[INFO] Creating Hugging Face dataset structure...");

Â  Â  let dataset_dir = "hf_dataset";

Â  Â  if !Path::new(dataset_dir).exists() {

Â  Â  Â  Â  match fs::create_dir_all(dataset_dir) {

Â  Â  Â  Â  Â  Â  Ok(_) => println!("[INFO] Created dataset directory: {}", dataset_dir),

Â  Â  Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  Â  Â  println!("[ERROR] Could not create dataset directory: {}", e);

Â  Â  Â  Â  Â  Â  Â  Â  return;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â 

Â  Â  // Create HF reports directory

Â  Â  let hf_reports_dir = format!("{}/reports", dataset_dir);

Â  Â  if !Path::new(&hf_reports_dir).exists() {

Â  Â  Â  Â  match fs::create_dir_all(&hf_reports_dir) {

Â  Â  Â  Â  Â  Â  Ok(_) => println!("[INFO] Created HF reports directory: {}", hf_reports_dir),

Â  Â  Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  Â  Â  println!("[ERROR] Could not create HF reports directory: {}", e);

Â  Â  Â  Â  Â  Â  Â  Â  return;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }



Â  Â  // 3. Analyze all files

Â  Â  println!("[INFO] Initializing CodeAnalyzer ...");

Â  Â  let mut analyzer = CodeAnalyzer::new(32, 0.8);

Â  Â  println!("[INFO] Analyzing files ...");

Â  Â  let analyses = match analyzer.analyze_multiple_files(files) {

Â  Â  Â  Â  Ok(a) => a,

Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  println!("[ERROR] Failed to analyze files: {}", e);

Â  Â  Â  Â  Â  Â  return;

Â  Â  Â  Â  }

Â  Â  };

Â  Â  println!("[INFO] Analysis complete. {} files analyzed.", analyses.len());



Â  Â  // 3. Set up reports directory

Â  Â  let reports_dir = "reports";

Â  Â  if !Path::new(reports_dir).exists() {

Â  Â  Â  Â  match fs::create_dir_all(reports_dir) {

Â  Â  Â  Â  Â  Â  Ok(_) => println!("[INFO] Created reports directory: {}", reports_dir),

Â  Â  Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  Â  Â  println!("[ERROR] Could not create reports directory: {}", e);

Â  Â  Â  Â  Â  Â  Â  Â  return;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }



Â  Â  fn count_types_recursive(value: &serde_json::Value, type_counts: &mut BTreeMap<String, usize>, total_nodes: &mut usize) {

Â  Â  Â  Â  match value {

Â  Â  Â  Â  Â  Â  serde_json::Value::Object(map) => {

Â  Â  Â  Â  Â  Â  Â  Â  *total_nodes += 1;

Â  Â  Â  Â  Â  Â  Â  Â  for (k, v) in map.iter() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *type_counts.entry(k.clone()).or_insert(0) += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  count_types_recursive(v, type_counts, total_nodes);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  serde_json::Value::Array(arr) => {

Â  Â  Â  Â  Â  Â  Â  Â  for v in arr {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  count_types_recursive(v, type_counts, total_nodes);

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  _ => {}

Â  Â  Â  Â  }

Â  Â  }

Â  Â  let mut dir_type_counts: HashMap<String, BTreeMap<String, usize>> = HashMap::new();

Â  Â  let mut total_type_counts: BTreeMap<String, usize> = BTreeMap::new();

Â  Â  let mut global_word_counts: BTreeMap<String, usize> = BTreeMap::new();

Â  Â  let mut global_word_emoji_counts: BTreeMap<String, usize> = BTreeMap::new();

Â  Â  for (i, analysis) in analyses.iter().enumerate() {

Â  Â  Â  Â  match serde_json::from_str::<serde_json::Value>(&analysis.json_ast) {

Â  Â  Â  Â  Â  Â  Ok(ast) => {

Â  Â  Â  Â  Â  Â  Â  Â  let mut type_counts = BTreeMap::new();

Â  Â  Â  Â  Â  Â  Â  Â  let mut total_nodes = 0;

Â  Â  Â  Â  Â  Â  Â  Â  count_types_recursive(&ast, &mut type_counts, &mut total_nodes);

Â  Â  Â  Â  Â  Â  Â  Â  // Extract string literals and process words

Â  Â  Â  Â  Â  Â  Â  Â  let mut string_literals = Vec::new();

Â  Â  Â  Â  Â  Â  Â  Â  extract_string_literals(&ast, &mut string_literals);

Â  Â  Â  Â  Â  Â  Â  Â  let mut word_counts = BTreeMap::new();

Â  Â  Â  Â  Â  Â  Â  Â  for s in &string_literals {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for word in split_words(s) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *word_counts.entry(word).or_insert(0) += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  // Map words to emojis

Â  Â  Â  Â  Â  Â  Â  Â  let mut word_emoji_counts = BTreeMap::new();

Â  Â  Â  Â  Â  Â  Â  Â  for (word, count) in &word_counts {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let (emoji, category) = emoji_for_type(word);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if emoji != "â“" && emoji != "â“ğŸ¤·" {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *word_emoji_counts.entry(emoji).or_insert(0usize) += *count;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  // Count emojis in string literals

Â  Â  Â  Â  Â  Â  Â  Â  let mut emoji_counts_in_strings = BTreeMap::new();

Â  Â  Â  Â  Â  Â  Â  Â  for s in &string_literals {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for ch in s.chars() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if ch.len_utf8() > 2 { // crude emoji filter

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let e = ch.to_string();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *emoji_counts_in_strings.entry(e).or_insert(0) += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  // Write enriched report file directly to HF dataset

Â  Â  let timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();

Â  Â  let node_count = ast.as_object().map(|o| o.len()).unwrap_or(0);

Â  Â  let report = serde_json::json!({

Â  Â  Â  Â  "file_path": analysis.file_path,

Â  Â  Â  Â  "timestamp": timestamp,

Â  Â  Â  Â  "summary": {

Â  Â  Â  Â  Â  Â  "top_level_nodes": node_count,

Â  Â  Â  Â  Â  Â  "total_nodes": total_nodes,

Â  Â  Â  Â  Â  Â  "type_counts": type_counts,

Â  Â  Â  Â  Â  Â  "string_literals": string_literals,

Â  Â  Â  Â  Â  Â  "word_counts": word_counts,

Â  Â  Â  Â  Â  Â  "word_emoji_counts": word_emoji_counts,

Â  Â  Â  Â  Â  Â  "emoji_counts_in_strings": emoji_counts_in_strings

Â  Â  Â  Â  },

Â  Â  Â  Â  "ast": ast

Â  Â  });

Â  Â 

Â  Â  // Directory aggregation

Â  Â  let dir = analysis.file_path.rsplit_once('/').map(|(d, _)| d).unwrap_or("");

Â  Â  let dir_entry = dir_type_counts.entry(dir.to_string()).or_default();

Â  Â  for (ty, count) in &type_counts {

Â  Â  Â  Â  *dir_entry.entry(ty.clone()).or_insert(0) += *count;

Â  Â  Â  Â  *total_type_counts.entry(ty.clone()).or_insert(0) += *count;

Â  Â  }

Â  Â 

Â  Â  Â  Â  // Create compact directory structure for HF dataset reports

Â  Â  let path_parts: Vec<&str> = analysis.file_path.split(['/', '\\']).collect();

Â  Â  let subdir_name = if path_parts.len() >= 3 {

Â  Â  Â  Â  let name = format!("{}_{}_{}", path_parts[0], path_parts[1], path_parts[2]);

Â  Â  Â  Â  if name.len() > 50 { name[..50].to_string() } else { name }

Â  Â  } else if path_parts.len() == 2 {

Â  Â  Â  Â  let name = format!("{}_{}", path_parts[0], path_parts[1]);

Â  Â  Â  Â  if name.len() > 50 { name[..50].to_string() } else { name }

Â  Â  } else if path_parts.len() == 1 {

Â  Â  Â  Â  let name = path_parts[0].to_string();

Â  Â  Â  Â  if name.len() > 50 { name[..50].to_string() } else { name }

Â  Â  } else {

Â  Â  Â  Â  "root".to_string()

Â  Â  };

Â  Â 

Â  Â  // Create a shorter filename to avoid Windows path length limits

Â  Â  let original_filename = path_parts.last().unwrap_or(&"unknown");

Â  Â  let short_filename = if original_filename.len() > 30 {

Â  Â  Â  Â  // Truncate long filenames to 30 chars

Â  Â  Â  Â  format!("{}.json", &original_filename[..30])

Â  Â  } else {

Â  Â  Â  Â  format!("{}.json", original_filename)

Â  Â  };

Â  Â  let hf_report_path = format!("{}/reports/{}/{}", dataset_dir, subdir_name, short_filename);

Â  Â 

Â  Â  // Create the subdirectory if it doesn't exist

Â  Â  let subdir_path = format!("{}/reports/{}", dataset_dir, subdir_name);

Â  Â  if !Path::new(&subdir_path).exists() {

Â  Â  Â  Â  if let Err(e) = fs::create_dir_all(&subdir_path) {

Â  Â  Â  Â  Â  Â  println!("[ERROR] Failed to create directory {}: {}", subdir_path, e);

Â  Â  Â  Â  Â  Â  continue;

Â  Â  Â  Â  }

Â  Â  }

Â  Â 

Â  Â  let report_json = serde_json::to_string_pretty(&report).unwrap();

Â  Â 

Â  Â  // Write to HF dataset reports directory

Â  Â  match fs::write(&hf_report_path, &report_json) {

Â  Â  Â  Â  Ok(_) => {

Â  Â  Â  Â  Â  Â 

Â  Â  Â  Â  Â  Â  // Structure summary

Â  Â  Â  Â  Â  Â  let mut emoji_counts = Vec::new();

Â  Â  Â  Â  Â  Â  let mut emoji_summary = String::new();

Â  Â  Â  Â  Â  Â  for (ty, count) in &type_counts {

Â  Â  Â  Â  Â  Â  Â  Â  let (emoji, category) = emoji_for_type(ty);

Â  Â  Â  Â  Â  Â  Â  Â  emoji_counts.push(format!("{}({})Ã—{}", emoji, ty, count));

Â  Â  Â  Â  Â  Â  Â  Â  emoji_summary.push_str(&emoji.repeat(*count.min(&10)));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  let emoji_counts_str = emoji_counts.join(" ");

Â  Â  Â  Â  Â  Â  let filename = format!("{}.json", path_parts.last().unwrap_or(&"unknown"));

Â  Â  Â  Â  Â  Â  if type_counts.is_empty() {

Â  Â  Â  Â  Â  Â  Â  Â  println!("{} | none |", filename);

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  println!("{} | {} | {}", filename, emoji_counts_str, emoji_summary);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Emojis found in string literals

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if !emoji_counts_in_strings.is_empty() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let mut emoji_strs = Vec::new();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (emoji, count) in &emoji_counts_in_strings {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  emoji_strs.push(format!("{}Ã—{}", emoji, count));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  println!("[emojis in strings] {}", emoji_strs.join(" "));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Words mapped to emojis

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if !word_emoji_counts.is_empty() {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let mut word_emoji_strs = Vec::new();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (emoji, count) in &word_emoji_counts {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  word_emoji_strs.push(format!("{}Ã—{}", emoji, count));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  println!("[words mapped to emojis] {}", word_emoji_strs.join(" "));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // Aggregate global word counts

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (word, count) in &word_counts {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *global_word_counts.entry(word.clone()).or_insert(0) += *count;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (emoji, count) in &word_emoji_counts {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *global_word_emoji_counts.entry(emoji.to_string()).or_insert(0) += *count;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Err(e) => println!("[ERROR] Failed to write report {}: {}", hf_report_path, e),

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  Â  Â  println!("[ERROR] Failed to parse AST: {}", e);

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }

Â  Â  // Print per-directory summary table

Â  Â  println!("\n=== Directory Emoji Summary Table ===");

Â  Â  let mut dir_keys: Vec<_> = dir_type_counts.keys().collect();

Â  Â  dir_keys.sort();

Â  Â  let mut global_dir_reports = Vec::new();

Â  Â  for dir in dir_keys {

Â  Â  Â  Â  let type_counts = &dir_type_counts[dir];

Â  Â  Â  Â  let mut emoji_counts = Vec::new();

Â  Â  Â  Â  let mut emoji_summary = String::new();

Â  Â  Â  Â  for (ty, count) in type_counts {

Â  Â  Â  Â  Â  Â  let (emoji, category) = emoji_for_type(ty);

Â  Â  Â  Â  Â  Â  emoji_counts.push(format!("{}({})Ã—{}", emoji, ty, count));

Â  Â  Â  Â  Â  Â  emoji_summary.push_str(&emoji.repeat((*count).min(10)));

Â  Â  Â  Â  }

Â  Â  Â  Â  let emoji_counts_str = emoji_counts.join(" ");

Â  Â  Â  Â  let mut report = String::new();

Â  Â  Â  Â  report.push_str(&format!("=== Directory Emoji Summary: {} ===\n", dir));

Â  Â  Â  Â  if type_counts.is_empty() {

Â  Â  Â  Â  Â  Â  report.push_str(&format!("none\n"));

Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  report.push_str(&format!("{} | {}\n", emoji_counts_str, emoji_summary));

Â  Â  Â  Â  }

Â  Â  Â  Â  // Per-directory word/category/emoji breakdown

Â  Â  Â  Â  let mut dir_word_counts: BTreeMap<String, usize> = BTreeMap::new();

Â  Â  Â  Â  let mut dir_word_emoji_counts: BTreeMap<String, usize> = BTreeMap::new();

Â  Â  Â  Â  // Aggregate words for this directory

Â  Â  Â  Â  for (i, analysis) in analyses.iter().enumerate() {

Â  Â  Â  Â  Â  Â  if let Some(file_dir) = analysis.file_path.rsplit_once('/').map(|(d, _)| d) {

Â  Â  Â  Â  Â  Â  Â  Â  if file_dir == dir {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if let Ok(ast) = serde_json::from_str::<serde_json::Value>(&analysis.json_ast) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let mut string_literals = Vec::new();

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extract_string_literals(&ast, &mut string_literals);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for s in &string_literals {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for word in split_words(s) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *dir_word_counts.entry(word).or_insert(0) += 1;

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for (word, count) in &dir_word_counts {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let (emoji, category) = emoji_for_type(word);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if emoji != "â“" && emoji != "â“ğŸ¤·" {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dir_word_emoji_counts.entry(emoji.to_string()).or_insert(0usize).saturating_add(*count);

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  // Word report

Â  Â  Â  Â  report.push_str("\n=== Directory Word Report ===\n");

Â  Â  Â  Â  report.push_str(&format!("{:<20} | {:<8} | {:<18} | {}\n", "word", "count", "category", "emoji"));

Â  Â  Â  Â  let mut word_keys: Vec<_> = dir_word_counts.keys().collect();

Â  Â  Â  Â  word_keys.sort();

Â  Â  Â  Â  let mut found_agave = false;

Â  Â  Â  Â  let mut found_css = false;

Â  Â  Â  Â  let mut found_crypto = false;

Â  Â  Â  Â  let mut found_version = false;

Â  Â  Â  Â  for word in word_keys.iter() {

Â  Â  Â  Â  Â  Â  let count = dir_word_counts[*word];

Â  Â  Â  Â  Â  Â  let (emoji, category) = emoji_for_type(word);

Â  Â  Â  Â  Â  Â  if *word == "agave" { found_agave = true; }

Â  Â  Â  Â  Â  Â  if ["px", "deg", "em", "rem", "vh", "vw", "animation", "transition", "absolute", "align", "app", "app_state", "accessibility"].contains(&word.as_str()) { found_css = true; }

Â  Â  Â  Â  Â  Â  if ["aead", "aeads", "aes", "argon2", "arc", "addr2line", "aarch64", "amd64", "armv8", "crypto", "curve25519", "ed25519", "elliptic", "fiat", "cbor"].contains(&word.as_str()) { found_crypto = true; }

Â  Â  Â  Â  Â  Â  if ["zm", "h", "v"].contains(&word.as_str()) { found_version = true; }

Â  Â  Â  Â  Â  Â  if emoji != "â“" && emoji != "â“ğŸ¤·" {

Â  Â  Â  Â  Â  Â  Â  Â  report.push_str(&format!("{:<20} | {:<8} | {:<18} | {}\n", word, count, category, emoji));

Â  Â  Â  Â  Â  Â  } else {

Â  Â  Â  Â  Â  Â  Â  Â  report.push_str(&format!("{:<20} | {:<8} | {:<18} |\n", word, count, category));

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  Â  Â  // Banners

Â  Â  Â  Â  if found_agave {

Â  Â  Â  Â  Â  Â  report.push_str("\nğŸŒµğŸŒµğŸŒµ AGAVE detected! This project is spicy! ğŸŒµğŸŒµğŸŒµ\n");

Â  Â  Â  Â  }

Â  Â  Â  Â  if found_css {

Â  Â  Â  Â  Â  Â  report.push_str("\nğŸ¨ CSS/Frontend detected! Styling and animation everywhere!\n");

Â  Â  Â  Â  }

Â  Â  Â  Â  if found_crypto {

Â  Â  Â  Â  Â  Â  report.push_str("\nğŸ”’ Crypto detected! Security is strong in this codebase.\n");

Â  Â  Â  Â  }

Â  Â  Â  Â  if found_version {

Â  Â  Â  Â  Â  Â  report.push_str("\nğŸ”¢ Versioning/Hash detected! Lots of unique IDs and versions.\n");

Â  Â  Â  Â  }

Â  Â  Â  Â  // Write to file

Â  Â  Â  Â  let safe_dir = if dir.is_empty() { "root".to_string() } else { dir.replace('/', "_") };

Â  Â  Â  Â  let report_path = format!("{}/summary_{}.txt", reports_dir, safe_dir);

Â  Â  Â  Â  match fs::write(&report_path, &report) {

Â  Â  Â  Â  Â  Â  Ok(_) => println!("[INFO] Wrote directory summary to {}", report_path),

Â  Â  Â  Â  Â  Â  Err(e) => println!("[ERROR] Failed to write directory summary {}: {}", report_path, e),

Â  Â  Â  Â  }

Â  Â  Â  Â  global_dir_reports.push((dir.clone(), report_path));

Â  Â  }

Â  Â  // Print total summary (minimal)

Â  Â  let mut total_report = String::new();

Â  Â  total_report.push_str("=== Total Emoji Summary Table ===\n");

Â  Â  total_report.push_str(&format!("{:<20} | {:<8} | {:<18} | {}\n", "Type", "Count", "Category", "Emoji"));

Â  Â  let mut type_keys: Vec<_> = total_type_counts.keys().collect();

Â  Â  type_keys.sort();

Â  Â  for ty in type_keys {

Â  Â  Â  Â  let count = total_type_counts[ty];

Â  Â  Â  Â  let (emoji, category) = emoji_for_type(ty);

Â  Â  Â  Â  total_report.push_str(&format!("{:<20} | {:<8} | {:<18} | {}\n", ty, count, category, emoji));

Â  Â  }

Â  Â  total_report.push_str(&format!("\n[INFO] Total files processed: {}\n", analyses.len()));

Â  Â  // Write total summary

Â  Â  let merged_path = format!("{}/summary_total.txt", reports_dir);

Â  Â  match fs::write(&merged_path, &total_report) {

Â  Â  Â  Â  Ok(_) => println!("[INFO] Wrote total summary to {}", merged_path),

Â  Â  Â  Â  Err(e) => println!("[ERROR] Failed to write total summary: {}", e),

Â  Â  }



Â  Â  // 5. Create Hugging Face Dataset Structure

Â  Â  println!("\n[INFO] Creating Hugging Face dataset structure...");

Â  Â 

Â  Â  // Create dataset metadata

Â  Â  let dataset_info = serde_json::json!({

Â  Â  Â  Â  "description": "Rust codebase AST analysis with emoji mapping",

Â  Â  Â  Â  "license": "agpl-3.0",

Â  Â  Â  Â  "features": {

Â  Â  Â  Â  Â  Â  "file_path": {"dtype": "string"},

Â  Â  Â  Â  Â  Â  "timestamp": {"dtype": "int64"},

Â  Â  Â  Â  Â  Â  "ast": {"dtype": "string"},

Â  Â  Â  Â  Â  Â  "summary": {

Â  Â  Â  Â  Â  Â  Â  Â  "dtype": "map",

Â  Â  Â  Â  Â  Â  Â  Â  "mapping": {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "top_level_nodes": {"dtype": "int64"},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "total_nodes": {"dtype": "int64"},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "type_counts": {"dtype": "map"},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "string_literals": {"dtype": "sequence", "feature": {"dtype": "string"}},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "word_counts": {"dtype": "map"},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "word_emoji_counts": {"dtype": "map"},

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "emoji_counts_in_strings": {"dtype": "map"}

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  },

Â  Â  Â  Â  "builder_name": "rust_ast_emoji",

Â  Â  Â  Â  "config_name": "default",

Â  Â  Â  Â  "version": {"version_str": "0.1.0"},

Â  Â  Â  Â  "splits": {

Â  Â  Â  Â  Â  Â  "train": {

Â  Â  Â  Â  Â  Â  Â  Â  "name": "train",

Â  Â  Â  Â  Â  Â  Â  Â  "num_bytes": 0,

Â  Â  Â  Â  Â  Â  Â  Â  "num_examples": 0,

Â  Â  Â  Â  Â  Â  Â  Â  "shard_lengths": []

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  });



Â  Â  // Write dataset info

Â  Â  let info_path = format!("{}/dataset_info.json", dataset_dir);

Â  Â  match fs::write(&info_path, serde_json::to_string_pretty(&dataset_info).unwrap()) {

Â  Â  Â  Â  Ok(_) => println!("[INFO] Wrote dataset info to {}", info_path),

Â  Â  Â  Â  Err(e) => println!("[ERROR] Failed to write dataset info: {}", e),

Â  Â  }



Â  Â  // Split ASTs into chunks and organize into subdirectories

Â  Â  let max_file_size = 1024 * 1024; // 1MB

Â  Â  let max_files_per_dir = 10000;

Â  Â  let mut current_chunk = Vec::new();

Â  Â  let mut current_chunk_size = 0;

Â  Â  let mut chunk_index = 0;

Â  Â  let mut file_index = 0;

Â  Â  let mut total_examples = 0;



Â  Â  // Create data directory

Â  Â  let data_dir = format!("{}/data", dataset_dir);

Â  Â  if !Path::new(&data_dir).exists() {

Â  Â  Â  Â  match fs::create_dir_all(&data_dir) {

Â  Â  Â  Â  Â  Â  Ok(_) => println!("[INFO] Created data directory: {}", data_dir),

Â  Â  Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  Â  Â  println!("[ERROR] Could not create data directory: {}", e);

Â  Â  Â  Â  Â  Â  Â  Â  return;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }



Â  Â  // Copy reports to dataset

Â  Â  let reports_data_dir = format!("{}/reports", dataset_dir);

Â  Â  if !Path::new(&reports_data_dir).exists() {

Â  Â  Â  Â  match fs::create_dir_all(&reports_data_dir) {

Â  Â  Â  Â  Â  Â  Ok(_) => println!("[INFO] Created reports directory: {}", reports_data_dir),

Â  Â  Â  Â  Â  Â  Err(e) => {

Â  Â  Â  Â  Â  Â  Â  Â  println!("[ERROR] Could not create reports directory: {}", e);

Â  Â  Â  Â  Â  Â  Â  Â  return;

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }





Â  Â 

Â  Â  // Write summary files directly to HF dataset

Â  Â  let summary_files = [

Â  Â  Â  Â  "summary_total.txt",

Â  Â  Â  Â  "emoji_mapping.txt"

Â  Â  ];

Â  Â 

Â  Â  for summary_file in &summary_files {

Â  Â  Â  Â  let source_path = format!("{}/{}", reports_dir, summary_file);

Â  Â  Â  Â  let target_path = format!("{}/reports/{}", dataset_dir, summary_file);

Â  Â  Â  Â 

Â  Â  Â  Â  if Path::new(&source_path).exists() {

Â  Â  Â  Â  Â  Â  match fs::copy(&source_path, &target_path) {

Â  Â  Â  Â  Â  Â  Â  Â  Ok(_) => println!("[INFO] Copied summary file: {}", summary_file),

Â  Â  Â  Â  Â  Â  Â  Â  Err(e) => println!("[ERROR] Failed to copy {}: {}", summary_file, e),

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  }

Â  Â  }



Â  Â  // Process each analysis and create chunks

Â  Â  for analysis in &analyses {

Â  Â  Â  Â  if let Ok(ast) = serde_json::from_str::<serde_json::Value>(&analysis.json_ast) {

Â  Â  Â  Â  Â  Â  let mut type_counts = BTreeMap::new();

Â  Â  Â  Â  Â  Â  let mut total_nodes = 0;

Â  Â  Â  Â  Â  Â  count_types_recursive(&ast, &mut type_counts, &mut total_nodes);

Â  Â  Â  Â  Â  Â 

Â  Â  Â  Â  Â  Â  let mut string_literals = Vec::new();

Â  Â  Â  Â  Â  Â  extract_string_literals(&ast, &mut string_literals);

Â  Â  Â  Â  Â  Â  let mut word_counts = BTreeMap::new();

Â  Â  Â  Â  Â  Â  for s in &string_literals {

Â  Â  Â  Â  Â  Â  Â  Â  for word in split_words(s) {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  *word_counts.entry(word).or_insert(0) += 1;

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â 

Â  Â  Â  Â  Â  Â  let mut word_emoji_counts = BTreeMap::new();

Â  Â  Â  Â  Â  Â  for (word, c



It looks like the provided Rust code is part of a larger program that analyzes Rust source files, extracts their Abstract Syntax Trees (ASTs) using syn, and then generates various reports and statistics, including an emoji-based classification.

The request specifically asks for "rules in Rust to classify these structures" from syn. While the existing emoji_for_type function already does this in a lookup-table fashion, let's consider how you might expand and formalize these classification rules within the Rust code for a more robust and extensible system, as well as how to use the extracted information for further analysis as hinted in the comments.

Here's how you could define and apply more explicit classification rules, and how to use the extracted data for "construction of new functions based on the statistics," etc.

Defining and Applying Classification Rules for Syn Structures
The syn crate represents Rust code as an Abstract Syntax Tree. To classify these structures, you're essentially mapping syn's AST node types (which are represented as strings in your serde_json::Value after serialization) to meaningful categories. Your EMOJI_TYPE_MAP is already doing this effectively.

To make these "rules" more explicit and potentially more dynamic, you could consider:

1. Enum-Based Classification
Instead of just a &[(&str, &str, &str)] array, you could define an enum for your categories and then implement a trait or a match statement to map syn node names to these categories. This provides type safety and better organization.

Rust

#[derive(Debug, PartialEq, Eq, PartialOrd, Ord)]
pub enum AstCategory {
    RustCore,
    WebCss,
    CryptoSecurity,
    ProjectSpecific,
    Internationalization,
    TestingBenchmarking,
    MiscGeneral,
    Versioning,
    Color,
    Numbers,
    Emoji,
    HeuristicStructural,
    Uncategorized,
}

impl AstCategory {
    pub fn from_node_name(name: &str) -> AstCategory {
        // This is where your "rules" would live.
        // You could use a large match statement, or iterate over a more structured map.
        match name {
            // Rust Core
            "fn" | "struct" | "enum" | "mod" | "use" | "impl" | "trait" | "const" | "static" |
            "type" | "ident" | "attrs" | "fields" | "meta" | "path" | "lit" | "tokens" |
            "expr" | "block" | "call" | "method" | "macro" | "trait_object" | "item" |
            "items" | "field" | "inputs" | "output" | "receiver" | "generics" | "lifetime" |
            "where_clause" | "tuple" | "tuple_struct" | "array" | "int" | "float" | "bool" |
            "char" | "str" | "closure" | "let" | "match" | "if" | "else_branch" |
            "then_branch" | "for_loop" | "while" | "loop" | "return" | "break" | "continue" |
            "assign" | "op" | "unary" | "binary" | "cast" | "index" | "range" | "slice" |
            "macro_rules" | "group" | "delim" | "punct" | "paren" | "bracket" | "brace" |
            "attr" | "name_value" | "value" | "style" | "method_call" | "dyn" | "mut" |
            "ref" | "self_ty" | "super" | "crate" | "macro_input" | "macro_output" |
            "params" | "args" | "arguments" | "arm" | "arms" | "variant" | "variants" |
            "fields_named" | "fields_unnamed" | "pat" | "stmt" | "stmts" | "ty" | "bound" |
            "bounds" | "vis" | "list" | "token" | "tree" | "segment" | "segments" |
            "assoc_type" | "async" | "await" | "base" | "body" | "colon_token" |
            "delimiter" | "angle_bracketed" | "cond" | "func" | "init" | "right" | "semi" |
            "semi_token" | "spacing" | "start" | "stream" | "try" | "bare_fn" |
            "bounded_ty" | "byte_str" | "cases" | "dot2_token" | "elem" | "elems" | "end" |
            "impl_trait" | "left" | "len" | "limits" | "move" | "named" | "or" |
            "parenthesized" | "reference" | "rename" | "repeat" | "rest" | "restricted" |
            "turbofish" | "typed" | "unnamed" | "unsafe" | "_" | "colon2_token" | "content" => AstCategory::RustCore,

            // Web/CSS
            "px" | "deg" | "em" | "rem" | "vh" | "vw" | "s" | "ms" | "animation" |
            "transition" | "absolute" | "align" | "app" | "app_state" | "accessibility" |
            "adapter" | "actions" | "action" | "active" => AstCategory::WebCss,

            // Crypto/Security/Systems
            "aead" | "aeads" | "aes" | "argon2" | "arc" | "addr2line" | "aarch64" |
            "amd64" | "armv8" | "crypto" | "curve25519" | "ed25519" | "elliptic" | "fiat" |
            "cbor" => AstCategory::CryptoSecurity,

            // Project-specific
            "agave" | "helius" => AstCategory::ProjectSpecific,

            // Internationalization
            "icu4x" | "cldr" | "chinese" | "hebrew" | "coptic" | "ethiopic" | "calendar" |
            "datetime" => AstCategory::Internationalization,

            // Testing/Benchmarking
            "criterion" | "benches" | "fuzz" | "examples" | "docs" => AstCategory::TestingBenchmarking,

            // Misc/General
            "algebra" | "analysis" | "analyze" | "account" | "accounts" | "dot" | "colon" | "bounded" => AstCategory::MiscGeneral,

            // Suffixes for versioning/hashes
            "zm" | "h" | "v" => AstCategory::Versioning,

            // Color codes (hex)
            "ff" | "00" | "ffffff" | "000000" => AstCategory::Color,

            // Numbers (for fun)
            "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" | "10" | "100" | "255" => AstCategory::Numbers,

            // Emoji codepoints
            "1f3a8" | "1f4dd" | "1f680" | "1f4a9" => AstCategory::Emoji,

            // Heuristic/structural
            "byte" | "parenthes" | "case" | "where_clause" => AstCategory::HeuristicStructural,
            
            _ => AstCategory::Uncategorized,
        }
    }
}
You can then integrate this into your analysis:

Rust

// In your main loop, when processing a type
let (emoji, category_str) = emoji_for_type(ty); // Still use the emoji map for display
let ast_category = AstCategory::from_node_name(ty); // Use the new enum for classification
// Now you have a strongly typed category for further processing
2. Rule-Based Classification with External Configuration
For more complex scenarios, especially if you want to modify classification rules without recompiling, you could load them from a configuration file (e.g., TOML, YAML, JSON).

Rust

// Example: rules.toml
// [categories.rust_core]
// nodes = ["fn", "struct", "enum", ...]
// emoji = "ğŸ¦€âš™ï¸"

// [categories.web_css]
// nodes = ["px", "deg", ...]
// emoji = "ğŸï¸"
You would then have a function to load and parse this configuration, and use it to build your internal EMOJI_TYPE_MAP or a similar structure. This is particularly useful if different projects have different "project-specific" categories.

3. More Sophisticated Pattern Matching for ASTs
For more advanced classification beyond just the node name, you might want to look for specific patterns within the AST. The syn crate allows you to traverse the AST. For example, you could write a rule to identify "builder patterns" or "error handling" constructs. This would involve:

syn::visit: Implementing syn::visit::Visit to walk the AST and identify patterns.

Custom Structs for Patterns: Defining Rust structs that represent the patterns you're looking for (e.g., a struct BuilderPattern that captures impl blocks with methods returning Self).

For instance, to find all struct definitions:

Rust

use syn::{File, Item};

fn find_structs(ast: &File) -> Vec<String> {
    let mut struct_names = Vec::new();
    for item in &ast.items {
        if let Item::Struct(item_struct) = item {
            struct_names.push(item_struct.ident.to_string());
        }
    }
    struct_names
}

// You'd call this after parsing the file into a syn::File
// let parsed_file = syn::parse_file(&analysis.source_code)?;
// let structs = find_structs(&parsed_file);
This kind of structural analysis goes beyond simple string matching and allows for deeper insights.

Utilizing Analysis for New Function Construction and Feedback Loops
Your "idea" section outlines an ambitious recursive feedback loop. Let's break down how the current analysis feeds into those goals and what further steps would be needed.

Extraction of Terms from Identifiers & Relationships
Your split_words function already extracts terms from identifiers and string literals. This is crucial for:

Term Frequency Analysis: The word_counts and global_word_counts are exactly this. They tell you which terms are most common.

Relationship Extraction: This is a more complex task. From ASTs, you can infer:

Call Graphs: Which functions call which other functions.

Data Flow: How data moves through variables and function arguments.

Structural Relationships: How structs and enums relate (e.g., composition, inheritance-like patterns through traits).

To extract these, you'd need to go beyond simple JSON parsing of the AST and use syn's capabilities to walk the AST and build a graph representation. Libraries like petgraph could then be used to represent and analyze these graphs.

Creation of Mathematical Model
A "mathematical model" in this context could mean several things:

Statistical Models: Based on your current work, you can create statistical models of code. For example:

Type Distribution: How common are fn, struct, impl in a given codebase or directory? Your type_counts and total_type_counts are building blocks for this.

Naming Conventions: What are the common patterns in ident (identifier) names? Your split_words and word_counts are great for this. You could build a model to predict the category of a file based on its AST node type distribution or common words.

Code Embeddings (Vector Embedding): Your comment "embed source into vector" points to this. This involves converting code (or its AST) into numerical vectors that capture its semantic meaning.

AST Embeddings: You could adapt existing techniques for natural language processing (NLP) to ASTs. Each node type, identifier, or literal could be given an embedding. The solfunmeme_dioxus::core::code_analyzer::CodeAnalyzer likely contributes to this.

Purpose: These vectors can be used for:

Similarity Search: Find similar code snippets or files.

Clustering: Group similar files together (duplicate detection, but more semantically aware).

Predictive Models: Predict code properties (e.g., bug proneness, performance characteristics).

Construction of New Functions (Dynamic Code Generation)
This is the most ambitious part: "a recursive feedback loop using LLMs and statistics to dynamically create new functions and models in real time."

Your current analysis provides the "statistics" and "analysis" part. To "construct new functions," you would need:

Code Generation Library: A library or custom logic that can programmatically build Rust code (e.g., using quote crate, though syn is mostly for parsing).

LLM Integration: This is where the "recursive feedback loop" comes in. An LLM (Large Language Model) could:

Analyze Reports: Consume your generated JSON reports (hf_dataset/reports/).

Identify Patterns/Needs: Based on the analysis (e.g., "many small, repetitive functions," "common utility patterns"), the LLM could suggest new, more generic functions or refactorings.

Generate Code: The LLM would then generate Rust code for these new functions or models.

Feedback: The newly generated code would then be fed back into your CodeAnalyzer for further analysis, allowing the system to iterate and refine.

This would be a complex undertaking, involving:

Prompt Engineering: Crafting effective prompts for the LLM to guide its code generation.

Validation: Rigorous testing and validation of generated code (e.g., compilation, unit tests, static analysis).

Orchestration: Managing the flow between analysis, LLM inference, code generation, and re-analysis.

Export Data for GUI
Your current setup directly writes JSON reports to hf_dataset/reports/ and aggregated summaries to reports/. This is an excellent foundation for a GUI:

JSON API: A GUI could directly consume these JSON files.

Visualization: Tools like D3.js (JavaScript), Plotly (Python/JS), or even simpler chart libraries could visualize the type_counts, word_counts, and word_emoji_counts.

Interactive Exploration: A GUI could allow users to drill down from total summaries to directory summaries, and then to individual file reports and their ASTs.

Refactoring and Next Steps for Your Code
The main function is quite long and handles many concerns. Consider refactoring it into smaller, more focused functions or modules:

file_discovery::discover_rust_files(): Encapsulate the WalkDir logic.

report_generator::generate_file_report(): A function that takes CodeAnalysis and generates the serde_json::Value report for a single file.

summary_generator::aggregate_summaries(): A function that processes all individual file reports to create the directory and total summaries.

dataset_exporter::export_to_hf_dataset(): Handles the creation of the Hugging Face dataset structure and copying files.

classification::emoji_for_type() and classification::AstCategory::from_node_name(): Centralize classification logic.

This will improve readability, testability, and maintainability as you expand on your ambitious goals.

In summary, your existing code provides a strong foundation for classifying syn structures using a lookup-based approach and generating valuable statistical reports. The next steps for more advanced classification and dynamic function generation involve leveraging syn for deeper AST pattern matching, implementing robust graph data structures for relationship extraction, and integrating with external tools (like LLMs) for dynamic code generation.